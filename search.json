[
  {
    "objectID": "lab_6_workbook.html",
    "href": "lab_6_workbook.html",
    "title": "ST117 Lab 6 Workbook",
    "section": "",
    "text": "Suppose we observe data \\(\\vec{x}=(1,0,0,1,0,1,0,0,1,1)\\) where each element \\(X_i\\) follows a Bernoulli distribution with an unknown success probability \\(p\\).\n\nFind the likelihood function \\(L(p;\\vec{x})\\) which represents the joint pdf function of \\(p\\) given the observed data \\(\\vec{x}\\) and define it as a function in R. Calculate the value of this function at \\(p=0.1\\).\n\n\n#TODO: write your codes here\n\n\nPlot the likelihood function for \\(p\\in[0,1]\\) and use the optimize() function to find the point that maximizes \\(L(p;\\vec{x})\\). Add a vertical line to the plot to indicate this maximum point.\n\n\n#TODO: write your codes here\n\n\nCalculate the log-likelihood function \\(l(p;\\vec{x})\\) and define this function in R. Plot the log-likelihood function. Verify that \\(p=0.5\\) maximizes the log-likelihood function by setting its first derivative equal to zero and ensuring that the second derivative is negative.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_workbook.html#bernoulli-distribution",
    "href": "lab_6_workbook.html#bernoulli-distribution",
    "title": "ST117 Lab 6 Workbook",
    "section": "",
    "text": "Suppose we observe data \\(\\vec{x}=(1,0,0,1,0,1,0,0,1,1)\\) where each element \\(X_i\\) follows a Bernoulli distribution with an unknown success probability \\(p\\).\n\nFind the likelihood function \\(L(p;\\vec{x})\\) which represents the joint pdf function of \\(p\\) given the observed data \\(\\vec{x}\\) and define it as a function in R. Calculate the value of this function at \\(p=0.1\\).\n\n\n#TODO: write your codes here\n\n\nPlot the likelihood function for \\(p\\in[0,1]\\) and use the optimize() function to find the point that maximizes \\(L(p;\\vec{x})\\). Add a vertical line to the plot to indicate this maximum point.\n\n\n#TODO: write your codes here\n\n\nCalculate the log-likelihood function \\(l(p;\\vec{x})\\) and define this function in R. Plot the log-likelihood function. Verify that \\(p=0.5\\) maximizes the log-likelihood function by setting its first derivative equal to zero and ensuring that the second derivative is negative.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_workbook.html#binomial-distribution",
    "href": "lab_6_workbook.html#binomial-distribution",
    "title": "ST117 Lab 6 Workbook",
    "section": "2. Binomial Distribution",
    "text": "2. Binomial Distribution\nGiven that \\(X \\sim \\text{Bin}(n,p)\\) and observed that \\(n=10\\) and \\(x=3\\).\n\nDefine the likelihood function in R and calculate it at \\(p=0.1\\).\n\n\n#TODO: write your codes here\n\n\nPlot the likelihood function for \\(p\\in[0,1]\\) and calculate the maximum likelihood estimate. Add a vertical line to the plot to indicate this maximum point.\n\n\n#TODO: write your codes here\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_workbook.html#normal-distribution",
    "href": "lab_6_workbook.html#normal-distribution",
    "title": "ST117 Lab 6 Workbook",
    "section": "3. Normal Distribution",
    "text": "3. Normal Distribution\nGiven the heights(in cm) of a random sample of 20 students:\n182, 154, 147, 150, 164, 177, 169, 173, 160, 173, 170, 160, 178, 175, 154, 179, 168, 188, 172, 162\nWe assume that the heights of students follow a normal distribution with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\n\nDetermine the maximum likelihood estimates of \\(\\mu\\) and \\(\\sigma\\) based on the given sample.\n\n\n#TODO: write your codes here\n\n\nCalculate the log-likelihood of these height estimates.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_1_markdown.html",
    "href": "lab_1_markdown.html",
    "title": "ST117 Lab 1",
    "section": "",
    "text": "Welcome to ST117 Introduction to Statistical Modelling Lab 1!\nIn this lab session, we will focus on how to collect, save, and read data in R. We will also discuss some ways to manipulate and visualise our datasets. You will also have the chance to share and present the data you have collected with your deskmates!\n\n\n\n\n\n\nAbout me\n\nEmail: mengqi.chen.2@warwick.ac.uk\nRoom: MB3.14"
  },
  {
    "objectID": "lab_1_markdown.html#saving-data-into-.csv-files",
    "href": "lab_1_markdown.html#saving-data-into-.csv-files",
    "title": "ST117 Lab 1",
    "section": "2.1 Saving data into .csv Files",
    "text": "2.1 Saving data into .csv Files\nHere’s a basic example of how to save a dataset into a .csv file in R:\n\n# Create a sample data frame\ndata &lt;- data.frame(\n  id = 1:10,\n  score = runif(10, min=0, max=100)\n)\n\n# Write the data frame to a CSV file\nwrite.csv(data, \"sample_data.csv\", row.names = FALSE)"
  },
  {
    "objectID": "lab_1_markdown.html#reading-csv-files",
    "href": "lab_1_markdown.html#reading-csv-files",
    "title": "ST117 Lab 1",
    "section": "2.2 Reading CSV Files",
    "text": "2.2 Reading CSV Files\nTo read a CSV file into R:\n\n# Read the CSV file\ndata_read &lt;- read.csv(\"sample_data.csv\", header = FALSE)"
  },
  {
    "objectID": "lab_1_markdown.html#finding-data-online",
    "href": "lab_1_markdown.html#finding-data-online",
    "title": "ST117 Lab 1",
    "section": "2.3 Finding data online",
    "text": "2.3 Finding data online\nDatasets can also be found in various online repositories, such as:\n\nKaggle is a popular platform for data science competitions, but it also hosts a wide variety of datasets. These datasets cover a range of topics and complexities and can be a great starting point for projects in statistical modelling, data science, and machine learning\nUCI Machine Learning Repository: The University of California, Irvine, maintains a repository of datasets specifically for machine learning. These datasets are well-documented and have been used in numerous academic papers, making them ideal for research.\n…\n\n\n\n\n\n\n\nYour turn!\n\n\n\n\nPlease share your A0-collect! datasets to your deskmate - you could use email, link sharing, USB, etc.\nIntroduce your datasets to each other - how have you collected the data? What questions are you trying to answer with your data?\nAfter you have received your deskmate’s datasets, try to load them into your R workspace."
  },
  {
    "objectID": "lab_1_markdown.html#meet-the-penguins",
    "href": "lab_1_markdown.html#meet-the-penguins",
    "title": "ST117 Lab 1",
    "section": "Meet the penguins",
    "text": "Meet the penguins\n\nThe penguins data from the palmerpenguins package contains size measurements for 344 penguins from three species observed on three islands in the Palmer Archipelago, Antarctica.\nWe will first install and load the packages:\n\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\n\nLet’s take a look at the penguins data:\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nWhat if we are interested in some specific aspects of the penguins?\n\nCalculate the mean body mass of penguins (similarly, you can use var for variance and median for median)\n\nmean(penguins$body_mass_g, na.rm = TRUE) # na.rm indicates whether we remove the NA values\n\n[1] 4201.754\n\n\nGet the 5 largest body masses\n\nhead(sort(penguins$body_mass_g, decreasing=TRUE), 5)\n\n[1] 6300 6050 6000 6000 5950\n\n\n\n\n\n\n\n\n\n*Introducing: dplyr package\n\n\n\nIn data science, dplyr is a very popular package. It is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges. To install and load dplyr:\n\n# Load the dplyr package for data manipulation\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\n\n\nWith dplyr, we can do more fun things with our dataset!\n\nCount how many penguins are in each species\n\ncount(penguins, species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nFilter the datasets to get the data for female Gentoos only:\n\nfilter(penguins, sex == \"female\", species == \"Gentoo\")\n\n# A tibble: 58 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           48.7          14.1               210        4450\n 3 Gentoo  Biscoe           46.5          13.5               210        4550\n 4 Gentoo  Biscoe           45.4          14.6               211        4800\n 5 Gentoo  Biscoe           43.3          13.4               209        4400\n 6 Gentoo  Biscoe           40.9          13.7               214        4650\n 7 Gentoo  Biscoe           45.5          13.7               214        4650\n 8 Gentoo  Biscoe           45.8          14.6               210        4200\n 9 Gentoo  Biscoe           42            13.5               210        4150\n10 Gentoo  Biscoe           46.2          14.5               209        4800\n# ℹ 48 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nGet the mean body mass of penguins by species\n\nsummarise(penguins, mean_body_mass = mean(body_mass_g, na.rm = TRUE),\n            .by = species)\n\n# A tibble: 3 × 2\n  species   mean_body_mass\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Adelie             3701.\n2 Gentoo             5076.\n3 Chinstrap          3733.\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\n\nUse these functions, or other ones that you like, investigate your and your deskmate’s datasets!\n\nIf you run into any problems, try solving them by checking the documentation, using the help function, and discussing with each other!\n\nShare your findings with your deskmate."
  },
  {
    "objectID": "activity1_template.html",
    "href": "activity1_template.html",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;This can be from an online source or a dataset you create manually. Describe the dataset briefly.&gt;\n\n\n\n&lt;Use R to load your dataset into a data frame. Show the code you used. You may use functions such as head() or glimpse(from dplyr) to display the data frame&gt;\n\n# Your R code to load (and display) the dataset \n\n\n\n\n&lt;Create a visualisation of the dataset. Consider the type of data and what you wish to convey.&gt;\n\n# Your R code for the visualisation\n\n\n\n\n&lt;Explain why you chose the type of plot, what it aims to show, and what insights it provides about the dataset’s context.&gt;"
  },
  {
    "objectID": "activity1_template.html#find-a-small-dataset",
    "href": "activity1_template.html#find-a-small-dataset",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;This can be from an online source or a dataset you create manually. Describe the dataset briefly.&gt;"
  },
  {
    "objectID": "activity1_template.html#load-the-dataset",
    "href": "activity1_template.html#load-the-dataset",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;Use R to load your dataset into a data frame. Show the code you used. You may use functions such as head() or glimpse(from dplyr) to display the data frame&gt;\n\n# Your R code to load (and display) the dataset"
  },
  {
    "objectID": "activity1_template.html#visualisation",
    "href": "activity1_template.html#visualisation",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;Create a visualisation of the dataset. Consider the type of data and what you wish to convey.&gt;\n\n# Your R code for the visualisation"
  },
  {
    "objectID": "activity1_template.html#explanation",
    "href": "activity1_template.html#explanation",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;Explain why you chose the type of plot, what it aims to show, and what insights it provides about the dataset’s context.&gt;"
  },
  {
    "objectID": "activity1_template.html#find-a-large-dataset",
    "href": "activity1_template.html#find-a-large-dataset",
    "title": "Activity 1: Data visualisation",
    "section": "2.1 Find a Large Dataset",
    "text": "2.1 Find a Large Dataset\n&lt;Look for a large dataset available online. Describe the dataset and its source.&gt;"
  },
  {
    "objectID": "activity1_template.html#load-the-dataset-1",
    "href": "activity1_template.html#load-the-dataset-1",
    "title": "Activity 1: Data visualisation",
    "section": "2.2 Load the Dataset",
    "text": "2.2 Load the Dataset\n&lt;Use R to load your dataset into a data frame. Show the code you used. You may use functions such as head() or glimpse(from dplyr) to display the data frame&gt;\n\n# Your R code to load (and display) the dataset"
  },
  {
    "objectID": "activity1_template.html#visualisation-1",
    "href": "activity1_template.html#visualisation-1",
    "title": "Activity 1: Data visualisation",
    "section": "2.3 Visualisation",
    "text": "2.3 Visualisation\n&lt;Create a visualisation that highlights key aspects of the dataset.&gt;\n\n# Your R code for the visualisation"
  },
  {
    "objectID": "activity1_template.html#explanation-1",
    "href": "activity1_template.html#explanation-1",
    "title": "Activity 1: Data visualisation",
    "section": "2.4 Explanation",
    "text": "2.4 Explanation\n&lt;Discuss your choice of visualisation, its relevance, and the insights it offers about the dataset.&gt;\n\n# Your written explanation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the website for the ST117 Introduction to Statistics Lab sessions. This site is regularly updated with lab notes for each session. It also contains a variety of resources to assist you in learning R and statistical modelling."
  },
  {
    "objectID": "index.html#useful-resources",
    "href": "index.html#useful-resources",
    "title": "Home",
    "section": "Useful Resources",
    "text": "Useful Resources\nThe following cheatsheets can be helpful for quick references:\n\nR Cheatsheet: A comprehensive guide to the basics of R programming.\nData-Wrangling Cheatsheet: A summary of various data-wrangling commands with packages dplyr and tidyr.\nggplot2 Cheatsheet: ggplot2 is a powerful tool for making custom plots in R. This cheatsheet provides a concise guide.\ntidyverse Cheatsheet: tdyverse is a collection of R packages designed for data science. This cheatsheet covers some of the most commonly used packages.\nR Markdown Cheatsheet: This cheatsheet provides a quick reference to the R Markdown syntax.\nStatistical Distributions Cheatsheet: A sheet summarising the properties of some basic discrete and continuous distributions.\nMathematics in R Markdown: This pages summarises common LaTex syntax for R markdown."
  },
  {
    "objectID": "index.html#feedback",
    "href": "index.html#feedback",
    "title": "Home",
    "section": "Feedback",
    "text": "Feedback\nPlease fill out the anonymous feedback form to help make the lab sessions better for everyone!"
  },
  {
    "objectID": "lab_4_markdown.html",
    "href": "lab_4_markdown.html",
    "title": "ST117 Lab 4",
    "section": "",
    "text": "1 minute per student\nR markdown template for this presentation\n\n\n\n\n\nsanity check\n\ndoes this make sense?\nis this what this question is asking?\ncross-check with your pod members!\n\nwork presentation style\n\nstructure: put the answers and codes for the same question together\ncomment your codes\n\ncreate tables for your data frame when it has many columns - use kable from knitr!\n\nlibrary(knitr)\ngrade_book &lt;- data.frame(\n  first_names=randomNames(288,which.names = \"first\"), \n  last_names=randomNames(288,which.names = \"last\"), \n  lab_groups=rep(1:16,times=18) # 16 groups of 18 students each\n) \nkable(head(grade_book))\n\n\n\n\nfirst_names\nlast_names\nlab_groups\n\n\n\n\nVictoria\nBrown\n1\n\n\nJammi\nRios\n2\n\n\nMichael\nToone\n3\n\n\nKaleb\nThomas\n4\n\n\nAiman\nHorblit\n5\n\n\nMaazin\nAskew\n6"
  },
  {
    "objectID": "lab_4_markdown.html#a1-activity-presentation-next-week",
    "href": "lab_4_markdown.html#a1-activity-presentation-next-week",
    "title": "ST117 Lab 4",
    "section": "",
    "text": "1 minute per student\nR markdown template for this presentation"
  },
  {
    "objectID": "lab_4_markdown.html#exercise-sheet-feedback-and-advice",
    "href": "lab_4_markdown.html#exercise-sheet-feedback-and-advice",
    "title": "ST117 Lab 4",
    "section": "",
    "text": "sanity check\n\ndoes this make sense?\nis this what this question is asking?\ncross-check with your pod members!\n\nwork presentation style\n\nstructure: put the answers and codes for the same question together\ncomment your codes\n\ncreate tables for your data frame when it has many columns - use kable from knitr!\n\nlibrary(knitr)\ngrade_book &lt;- data.frame(\n  first_names=randomNames(288,which.names = \"first\"), \n  last_names=randomNames(288,which.names = \"last\"), \n  lab_groups=rep(1:16,times=18) # 16 groups of 18 students each\n) \nkable(head(grade_book))\n\n\n\n\nfirst_names\nlast_names\nlab_groups\n\n\n\n\nVictoria\nBrown\n1\n\n\nJammi\nRios\n2\n\n\nMichael\nToone\n3\n\n\nKaleb\nThomas\n4\n\n\nAiman\nHorblit\n5\n\n\nMaazin\nAskew\n6"
  },
  {
    "objectID": "lab_4_markdown.html#inserting-images",
    "href": "lab_4_markdown.html#inserting-images",
    "title": "ST117 Lab 4",
    "section": "2.1 Inserting images",
    "text": "2.1 Inserting images\nInclude the pictures in R markdown with the following code, ![Name](path to the picture){width=50%}.\nExercise: Insert a image of your choice to the workbook.\n\n\n\nA picture of Squirrel"
  },
  {
    "objectID": "lab_4_markdown.html#mathematics-inside-rmarkdown",
    "href": "lab_4_markdown.html#mathematics-inside-rmarkdown",
    "title": "ST117 Lab 4",
    "section": "2.2 Mathematics inside RMarkdown",
    "text": "2.2 Mathematics inside RMarkdown\nThe mathematical typesetting is based on LaTeX. Below are some common LaTex syntax examples. A more comprehensive summary can be found on this page.\n\nSubscript \\(X_{i}\\): $X_{i}$\nSuperscript \\(X^{i}\\): $X^{i}$\nSum \\(\\sum_{i=1}^{n} X_{i}\\): $\\sum_{i=1}^{n} X_{i}$\nFraction \\(\\frac{a}{b}\\): $\\frac{a}{b}$\nExpectation \\(\\mathbb{E}[X]\\): $\\mathbb{E}[X]$\nVariance \\(\\operatorname{Var}\\): $\\operatorname{Var}$\nInfinity \\(\\infty\\): $\\infty$\nGreek letters \\(\\alpha\\): $\\alpha$\nAligning equations: use align\n\\[\n\\begin{align}\n\\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n&= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n&= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n&= \\lambda\n\\end{align}\n\\]\n$$\n\\begin{align}\n  \\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n  &= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n  &= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n  &= \\lambda\n\\end{align}\n$$\n\nExercise: Type out the following equation in LaTex:\n\n\n\nSecond moment of Poisson"
  },
  {
    "objectID": "lab_4_markdown.html#data-generation",
    "href": "lab_4_markdown.html#data-generation",
    "title": "ST117 Lab 4",
    "section": "3.1 Data Generation",
    "text": "3.1 Data Generation\nSuppose we have test scores for a population of 1000 students, expressed as percentages, generated from a \\(\\text{Beta}(2,5)\\) distribution. Create a data frame to store the names and scores of these students. Calculate the population mean and variance, and plot a histogram to visualize the distribution of the test scores."
  },
  {
    "objectID": "lab_4_markdown.html#mean-calculation",
    "href": "lab_4_markdown.html#mean-calculation",
    "title": "ST117 Lab 4",
    "section": "3.2 Mean Calculation:",
    "text": "3.2 Mean Calculation:\nSuppose that we only have access to a sample of 100 scores (with replacement). Please generate this sample and calculate its mean to estimate the population mean. Compute the bias of this estimator."
  },
  {
    "objectID": "lab_4_markdown.html#simulation-analysis-with-replacement-vs-without-replacement",
    "href": "lab_4_markdown.html#simulation-analysis-with-replacement-vs-without-replacement",
    "title": "ST117 Lab 4",
    "section": "3.3 Simulation Analysis: with replacement vs without replacement",
    "text": "3.3 Simulation Analysis: with replacement vs without replacement\n\nSuppose that we can repeat the survey process through 100,000 simulations, each sampling 100 students with replacement. Calculate the sample mean for each of the 100,000 simulations.\nCheck the mean, bias, and variance of the sample means.\nPlot a histogram of sample means. Compare the sample mean to a normal distribution using a Q-Q plot.\nSuppose we sample without replacement from the 100,000 simulations. Estimate the expectation, bias, and variance of the estimators. What did you learn about these quantities in your lectures? Type up the theoretical expressions of them with LaTex."
  },
  {
    "objectID": "lab_4_markdown.html#assigning-groups",
    "href": "lab_4_markdown.html#assigning-groups",
    "title": "ST117 Lab 4",
    "section": "3.4 Assigning groups",
    "text": "3.4 Assigning groups\nThe survey is conducted by two volunteer groups, 1 and 2, after we have randomly assigned students to these groups. A student is assigned to group 1 with probability \\(\\frac{2}{3}\\). Students attending the survey from group 1 receive a notebook, while those attending by group 2 receive a bottle. Create two columns to show which volunteer group conducted the survey and what gift the students received by sample() and ifelse()."
  },
  {
    "objectID": "lab_4_markdown.html#trimmed-mean-optional",
    "href": "lab_4_markdown.html#trimmed-mean-optional",
    "title": "ST117 Lab 4",
    "section": "3.5 Trimmed mean (optional)",
    "text": "3.5 Trimmed mean (optional)\nThe trimmed mean is a method to estimate a dataset’s central tendency by removing a specified percentage of the smallest and largest values before calculating the average of the remaining data. This technique helps reduce the impact of outliers, providing a more reliable measure of the dataset’s typical value, especially useful when data is skewed or contains extreme values. It combines the mean’s sensitivity to data changes with the median’s resistance to outliers, offering a robust tool for data analysis.\nIn R, we can calculate the trimmed mean via\n\nsample &lt;- pop[sample(nrow(pop), size=100,replace=TRUE),]\ntrim_means &lt;- mean(sample$scores, trim=0.2) # trim the smallest 10% and largest 10% before calculating the mean.\n\nAssume that our sampled data is contaminated with outliers: some students did not report their true score - a random selection of 5 student reported that their score is 1 regardless of their true score. Please include this contamination, and compare the mean and trimmed mean of your sample."
  },
  {
    "objectID": "lab_4_workbook.html",
    "href": "lab_4_workbook.html",
    "title": "ST117 Lab 4 Workbook",
    "section": "",
    "text": "Include the pictures in R markdown with the following code, ![Name](path to the picture){width=50%}.\nExercise: Insert a image of your choice to the workbook.\nTODO: Please insert your image here\n\n\n\nThe mathematical typesetting is based on LaTeX. Below are some common LaTex syntax examples.\n\nSubscript \\(X_{i}\\): $X_{i}$\nSuperscript \\(X^{i}\\): $X^{i}$\nSum \\(\\sum_{i=1}^{n} X_{i}\\): $\\sum_{i=1}^{n} X_{i}$\nFraction \\(\\frac{a}{b}\\): $\\frac{a}{b}$\nExpectation \\(\\mathbb{E}[X]\\): $\\mathbb{E}[X]$\nVariance \\(\\operatorname{Var}\\): $\\operatorname{Var}$\nInfinity \\(\\infty\\): $\\infty$\nGreek letters \\(\\alpha\\): $\\alpha$\nAligning equations: use aligned\n\\[\n\\begin{aligned}\n\\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n&= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n&= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n&= \\lambda\n\\end{aligned}\n\\]\n$$\n\\begin{aligned}\n  \\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n  &= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n  &= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n  &= \\lambda\n\\end{aligned}\n$$\n\nExercise: Type out the following equation in LaTex:\n\n\n\nSecond moment of Poisson\n\n\nTODO: LaTex codes \\[\n% type out your equation here\n\\]"
  },
  {
    "objectID": "lab_4_workbook.html#inserting-images",
    "href": "lab_4_workbook.html#inserting-images",
    "title": "ST117 Lab 4 Workbook",
    "section": "",
    "text": "Include the pictures in R markdown with the following code, ![Name](path to the picture){width=50%}.\nExercise: Insert a image of your choice to the workbook.\nTODO: Please insert your image here"
  },
  {
    "objectID": "lab_4_workbook.html#mathematics-inside-rmarkdown",
    "href": "lab_4_workbook.html#mathematics-inside-rmarkdown",
    "title": "ST117 Lab 4 Workbook",
    "section": "",
    "text": "The mathematical typesetting is based on LaTeX. Below are some common LaTex syntax examples.\n\nSubscript \\(X_{i}\\): $X_{i}$\nSuperscript \\(X^{i}\\): $X^{i}$\nSum \\(\\sum_{i=1}^{n} X_{i}\\): $\\sum_{i=1}^{n} X_{i}$\nFraction \\(\\frac{a}{b}\\): $\\frac{a}{b}$\nExpectation \\(\\mathbb{E}[X]\\): $\\mathbb{E}[X]$\nVariance \\(\\operatorname{Var}\\): $\\operatorname{Var}$\nInfinity \\(\\infty\\): $\\infty$\nGreek letters \\(\\alpha\\): $\\alpha$\nAligning equations: use aligned\n\\[\n\\begin{aligned}\n\\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n&= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n&= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n&= \\lambda\n\\end{aligned}\n\\]\n$$\n\\begin{aligned}\n  \\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n  &= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n  &= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n  &= \\lambda\n\\end{aligned}\n$$\n\nExercise: Type out the following equation in LaTex:\n\n\n\nSecond moment of Poisson\n\n\nTODO: LaTex codes \\[\n% type out your equation here\n\\]"
  },
  {
    "objectID": "lab_4_workbook.html#data-generation",
    "href": "lab_4_workbook.html#data-generation",
    "title": "ST117 Lab 4 Workbook",
    "section": "Data Generation",
    "text": "Data Generation\nSuppose we have test scores for a population of 1000 students, expressed as percentages, generated from a \\(\\text{Beta}(2,5)\\) distribution. Create a data frame to store the names and scores of these students. Calculate the population mean and variance, and plot a histogram to visualize the distribution of the test scores.\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_4_workbook.html#mean-calculation",
    "href": "lab_4_workbook.html#mean-calculation",
    "title": "ST117 Lab 4 Workbook",
    "section": "Mean Calculation:",
    "text": "Mean Calculation:\nSuppose that we only have access to a sample of 100 scores (with replacement). Please generate this sample and calculate its mean to estimate the population mean. Compute the bias of this estimator.\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_4_workbook.html#simulation-analysis-with-replacement-vs-without-replacement",
    "href": "lab_4_workbook.html#simulation-analysis-with-replacement-vs-without-replacement",
    "title": "ST117 Lab 4 Workbook",
    "section": "Simulation Analysis: with replacement vs without replacement",
    "text": "Simulation Analysis: with replacement vs without replacement\n\nSuppose that we can repeat the survey process through 100,000 simulations, each sampling 100 students with replacement. Calculate the sample mean for each of the 100,000 simulations.\n\n\n# TODO: write your codes here\n\n\nCheck the mean, bias, and variance of the sample means.\n\n\n# TODO: write your codes here\n\n\nPlot a histogram of sample means. Compare the sample mean to a normal distribution using a Q-Q plot.\n\n\n# TODO: write your codes here\n\n\nSuppose we sample without replacement from the 100,000 simulations. Estimate the expectation, bias, and variance of the estimators. What did you learn about these quantities in your lectures? Type up the theoretical expressions of them with LaTex.\n\n\n# TODO: write your codes here\n\nTODO: Latex codes \\[\n% write your LaTex expressions here\n\\]"
  },
  {
    "objectID": "lab_4_workbook.html#assigning-groups",
    "href": "lab_4_workbook.html#assigning-groups",
    "title": "ST117 Lab 4 Workbook",
    "section": "Assigning groups",
    "text": "Assigning groups\nThe survey is conducted by two volunteer groups, 1 and 2, after we have randomly assigned students to these groups. A student is assigned to group 1 with probability \\(\\frac{2}{3}\\). Students attending the survey from group 1 receive a notebook, while those attending by group 2 receive a bottle. Create two columns to show which volunteer group conducted the survey and what gift the students received by sample() and ifelse().\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_4_workbook.html#trimmed-mean-optional",
    "href": "lab_4_workbook.html#trimmed-mean-optional",
    "title": "ST117 Lab 4 Workbook",
    "section": "Trimmed mean (optional)",
    "text": "Trimmed mean (optional)\nThe trimmed mean is a method to estimate a dataset’s central tendency by removing a specified percentage of the smallest and largest values before calculating the average of the remaining data. This technique helps reduce the impact of outliers, providing a more reliable measure of the dataset’s typical value, especially useful when data is skewed or contains extreme values. It combines the mean’s sensitivity to data changes with the median’s resistance to outliers, offering a robust tool for data analysis.\nIn R, we can calculate the trimmed mean via\n\nsample &lt;- pop[sample(nrow(pop), size=100,replace=TRUE),]\ntrim_means &lt;- mean(sample$scores, trim=0.2) # trim the smallest 10% and largest 10% before calculating the mean.\n\nAssume that our sampled data is contaminated with outliers: some students did not report their true score - a random selection of 5 student reported that their score is 1 regardless of their true score. Please include this contamination, and compare the mean and trimmed mean of your sample.\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_3_workbook.html",
    "href": "lab_3_workbook.html",
    "title": "ST117 Lab 3 Workbook",
    "section": "",
    "text": "Generate a random sample of 1000 observations from a binomial distribution with parameters \\(n=20\\) and \\(p=0.5\\), then create a histogram to visualize the distribution.\n\n\n# TODO: generate binomial samples\n\n\n# TODO: write down your codes to plot the histogram\n\n\nCalculate the mean and standard deviation of the generated data. Compare these values with the theoretical mean and variance.\n\n\n# TODO: calculate mean and variance\n\n\nFlipping a coin 20 times, where it has 50% chance of getting a head. The total number of head \\(X\\) follows a Binomial distribution with \\(n=20\\) and \\(p=0.5\\). Find the probability of getting between 5 and 12 heads when tossing 20 coins, which is sum of the orange bars.\n\n\n\n\n\n\n\n\n\n\n\n# TODO: calculate the probability"
  },
  {
    "objectID": "lab_3_workbook.html#simulating-and-visualizing-binomial-distribution",
    "href": "lab_3_workbook.html#simulating-and-visualizing-binomial-distribution",
    "title": "ST117 Lab 3 Workbook",
    "section": "",
    "text": "Generate a random sample of 1000 observations from a binomial distribution with parameters \\(n=20\\) and \\(p=0.5\\), then create a histogram to visualize the distribution.\n\n\n# TODO: generate binomial samples\n\n\n# TODO: write down your codes to plot the histogram\n\n\nCalculate the mean and standard deviation of the generated data. Compare these values with the theoretical mean and variance.\n\n\n# TODO: calculate mean and variance\n\n\nFlipping a coin 20 times, where it has 50% chance of getting a head. The total number of head \\(X\\) follows a Binomial distribution with \\(n=20\\) and \\(p=0.5\\). Find the probability of getting between 5 and 12 heads when tossing 20 coins, which is sum of the orange bars.\n\n\n\n\n\n\n\n\n\n\n\n# TODO: calculate the probability"
  },
  {
    "objectID": "lab_3_workbook.html#calculating-probabilities-from-the-normal-distribution",
    "href": "lab_3_workbook.html#calculating-probabilities-from-the-normal-distribution",
    "title": "ST117 Lab 3 Workbook",
    "section": "2. Calculating Probabilities from the Normal Distribution",
    "text": "2. Calculating Probabilities from the Normal Distribution\n\nSuppose \\(X \\sim \\text{N}(0,1)\\), find the value \\(m\\) (green point) such that \\(P(X\\leq m)=0.95\\).\n\n\n\n\n\n\n\n\n\n\n\n# TODO: find m with qnorm\n\n\nGiven \\(X \\sim \\text{N}(2,0.7^2)\\), find the probability of \\(X\\) being between 1 and 4.\n\n\n# TODO: calculate the probability\n\n\nFind the probability \\(P(5\\leq X\\leq 12)\\) for \\(X \\sim \\text{N}(10,5)\\).\n\n\n# TODO: calculate the probability"
  },
  {
    "objectID": "lab_3_workbook.html#approximating-the-binomial-with-the-normal-distribution",
    "href": "lab_3_workbook.html#approximating-the-binomial-with-the-normal-distribution",
    "title": "ST117 Lab 3 Workbook",
    "section": "3. Approximating the Binomial with the Normal distribution",
    "text": "3. Approximating the Binomial with the Normal distribution\nPlease write down the questions and answers yourself, following the format above."
  },
  {
    "objectID": "lab_3_markdown.html",
    "href": "lab_3_markdown.html",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "This lab session aims to familiarize you with the use of R for basic statistical analysis. We will cover various distributions, their properties, and how to use R to work with these distributions.\n\n\n\n\n\n\n\n\n\n\n\nDistribution\nParameters\nSample Command\nDensity Function\nDistribution Function\nQuantile Function\n\n\n\n\nUniform\nmin, max\nrunif(n, min, max)\ndunif(x, min, max)\npunif(q, min, max)\nqunif(p, min, max)\n\n\nBinomial\nsize, prob\nrbinom(n, size, prob)\ndbinom(x, size, prob)\npbinom(q, size, prob)\nqbinom(p, size, prob)\n\n\nPoisson\nlambda\nrpois(n, lambda)\ndpois(x, lambda)\nppois(q, lambda)\nqpois(p, lambda)\n\n\nNormal\nmean, sd\nrnorm(n, mean, sd)\ndnorm(x, mean, sd)\npnorm(q, mean, sd)\nqnorm(p, mean, sd)\n\n\nGamma\nshape, rate\nrgamma(n, shape, rate)\ndgamma(x, shape, rate)\npgamma(q, shape, rate)\nqgamma(p, shape, rate)\n\n\nBeta\nshape1, shape2\nrbeta(n, shape1, shape2)\ndbeta(x, shape1, shape2)\npbeta(q, shape1, shape2)\nqbeta(p, shape1, shape2)\n\n\n\n\n\n\n# Drawing 200 samples from a binomial distribution\nsample_size &lt;- 200\nsize &lt;- 10\nprob &lt;- 0.7\nbinom_samples &lt;- rbinom(sample_size, size, prob)\n\n\n\n\nNext, let us plot the histogram of the samples.\n\n# Plotting histogram with density overlay\nhist(binom_samples, probability = TRUE, main = \"Samples from Bin(10,0.7)\", xlab = \"Values\", ylab = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nThe following code calculates the mean, variance, and standard deviation of the samples.\n\n# Calculating mean, variance, and standard deviation\nmean_value &lt;- mean(binom_samples)\nsprintf(\"mean = %s\", mean_value)\n\n[1] \"mean = 6.935\"\n\nvariance_value &lt;- var(binom_samples)\nsprintf(\"variance = %s\", variance_value)\n\n[1] \"variance = 2.11133165829146\"\n\nsd_value &lt;- sqrt(var(binom_samples))\nsprintf(\"standard deviation = %s\", sd_value)\n\n[1] \"standard deviation = 1.45304220802132\"\n\n\n\n\n\nRecall that we have \\(X \\sim \\operatorname{Bin}(10,0.7)\\).\n\nWhat is the probability \\(P(X = 6)\\)?\n\n\n# use \"d+dist\" to calculate the density at a point\np_6 &lt;- dbinom(6,10,0.7)\nsprintf(\"P(X=6) = %s\", p_6)\n\n[1] \"P(X=6) = 0.200120949\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen d+dist(\\(x\\)) is the density of \\(X\\) at \\(x\\), and \\(P(X=x)=0\\) for all \\(x\\).\n\n\n\nWhat is the probability \\(P(2\\leq X \\leq 5)\\)?\n\n\n# use \"p+dist\" to calculate P(X&lt;=a)\np_less_than_5 &lt;- pbinom(5,10,0.7)\np_less_than_1 &lt;- pbinom(1,10,0.7)\np_2to5 &lt;- p_less_than_5 - p_less_than_1\nsprintf(\"P(2&lt;=X&lt;=5) = %s\", p_2to5)\n\n[1] \"P(2&lt;=X&lt;=5) = 0.1501246467\"\n\n\n\nWhat is the smallest value of \\(a\\) such that \\(P(X\\leq a) \\geq 0.5\\)?\n\n\n# let's take a look at the distribution function first:\ndist_df = data.frame(\n  a = 0:10,\n  p_x_lessthan_a = pbinom(0:10,10,0.7)\n)\ndist_df\n\n    a p_x_lessthan_a\n1   0   0.0000059049\n2   1   0.0001436859\n3   2   0.0015903864\n4   3   0.0105920784\n5   4   0.0473489874\n6   5   0.1502683326\n7   6   0.3503892816\n8   7   0.6172172136\n9   8   0.8506916541\n10  9   0.9717524751\n11 10   1.0000000000\n\n\n\n# can use \"q+dist\" to find such a\nquantile &lt;- qbinom(0.5,10,0.7)\nsprintf(\"a = %s\", quantile)\n\n[1] \"a = 7\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen q+dist(\\(q\\)) is a one to one function giving precisely the \\(a\\) such that \\(P(X\\leq a)=q\\).\n\n\n\n\n\nWe have that if \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\), then \\(aX+b\\sim \\mathcal{N}(a\\mu+b,a^2\\sigma^2)\\). This property is useful when we want to transform a standard \\(\\mathcal{N}(0,1)\\) to match a given set of mean and variance."
  },
  {
    "objectID": "lab_3_markdown.html#drawing-samples-from-a-given-distribution",
    "href": "lab_3_markdown.html#drawing-samples-from-a-given-distribution",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "# Drawing 200 samples from a binomial distribution\nsample_size &lt;- 200\nsize &lt;- 10\nprob &lt;- 0.7\nbinom_samples &lt;- rbinom(sample_size, size, prob)"
  },
  {
    "objectID": "lab_3_markdown.html#histogram",
    "href": "lab_3_markdown.html#histogram",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "Next, let us plot the histogram of the samples.\n\n# Plotting histogram with density overlay\nhist(binom_samples, probability = TRUE, main = \"Samples from Bin(10,0.7)\", xlab = \"Values\", ylab = \"Density\")"
  },
  {
    "objectID": "lab_3_markdown.html#mean-and-variance",
    "href": "lab_3_markdown.html#mean-and-variance",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "The following code calculates the mean, variance, and standard deviation of the samples.\n\n# Calculating mean, variance, and standard deviation\nmean_value &lt;- mean(binom_samples)\nsprintf(\"mean = %s\", mean_value)\n\n[1] \"mean = 6.935\"\n\nvariance_value &lt;- var(binom_samples)\nsprintf(\"variance = %s\", variance_value)\n\n[1] \"variance = 2.11133165829146\"\n\nsd_value &lt;- sqrt(var(binom_samples))\nsprintf(\"standard deviation = %s\", sd_value)\n\n[1] \"standard deviation = 1.45304220802132\""
  },
  {
    "objectID": "lab_3_markdown.html#probability-and-quantiles",
    "href": "lab_3_markdown.html#probability-and-quantiles",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "Recall that we have \\(X \\sim \\operatorname{Bin}(10,0.7)\\).\n\nWhat is the probability \\(P(X = 6)\\)?\n\n\n# use \"d+dist\" to calculate the density at a point\np_6 &lt;- dbinom(6,10,0.7)\nsprintf(\"P(X=6) = %s\", p_6)\n\n[1] \"P(X=6) = 0.200120949\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen d+dist(\\(x\\)) is the density of \\(X\\) at \\(x\\), and \\(P(X=x)=0\\) for all \\(x\\).\n\n\n\nWhat is the probability \\(P(2\\leq X \\leq 5)\\)?\n\n\n# use \"p+dist\" to calculate P(X&lt;=a)\np_less_than_5 &lt;- pbinom(5,10,0.7)\np_less_than_1 &lt;- pbinom(1,10,0.7)\np_2to5 &lt;- p_less_than_5 - p_less_than_1\nsprintf(\"P(2&lt;=X&lt;=5) = %s\", p_2to5)\n\n[1] \"P(2&lt;=X&lt;=5) = 0.1501246467\"\n\n\n\nWhat is the smallest value of \\(a\\) such that \\(P(X\\leq a) \\geq 0.5\\)?\n\n\n# let's take a look at the distribution function first:\ndist_df = data.frame(\n  a = 0:10,\n  p_x_lessthan_a = pbinom(0:10,10,0.7)\n)\ndist_df\n\n    a p_x_lessthan_a\n1   0   0.0000059049\n2   1   0.0001436859\n3   2   0.0015903864\n4   3   0.0105920784\n5   4   0.0473489874\n6   5   0.1502683326\n7   6   0.3503892816\n8   7   0.6172172136\n9   8   0.8506916541\n10  9   0.9717524751\n11 10   1.0000000000\n\n\n\n# can use \"q+dist\" to find such a\nquantile &lt;- qbinom(0.5,10,0.7)\nsprintf(\"a = %s\", quantile)\n\n[1] \"a = 7\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen q+dist(\\(q\\)) is a one to one function giving precisely the \\(a\\) such that \\(P(X\\leq a)=q\\)."
  },
  {
    "objectID": "lab_3_markdown.html#linear-transformations-of-normal-random-variables",
    "href": "lab_3_markdown.html#linear-transformations-of-normal-random-variables",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "We have that if \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\), then \\(aX+b\\sim \\mathcal{N}(a\\mu+b,a^2\\sigma^2)\\). This property is useful when we want to transform a standard \\(\\mathcal{N}(0,1)\\) to match a given set of mean and variance."
  },
  {
    "objectID": "lab_3_markdown.html#simulating-and-visualizing-binomial-distribution",
    "href": "lab_3_markdown.html#simulating-and-visualizing-binomial-distribution",
    "title": "ST117 Lab 3",
    "section": "2.1 Simulating and Visualizing Binomial Distribution",
    "text": "2.1 Simulating and Visualizing Binomial Distribution\n\nGenerate a random sample of 1000 observations from a binomial distribution with parameters \\(n=20\\) and \\(p=0.5\\), then create a histogram to visualize the distribution.\nCalculate the mean and standard deviation of the generated data. Compare these values with the theoretical mean and variance.\nFlipping a coin 20 times, where it has 50% chance of getting a head. The total number of head \\(X\\) follows a Binomial distribution with \\(n=20\\) and \\(p=0.5\\). Find the probability of getting between 5 and 12 heads when tossing 20 coins, which is sum of the orange bars."
  },
  {
    "objectID": "lab_3_markdown.html#calculating-probabilities-from-the-normal-distribution",
    "href": "lab_3_markdown.html#calculating-probabilities-from-the-normal-distribution",
    "title": "ST117 Lab 3",
    "section": "2.2 Calculating Probabilities from the Normal Distribution",
    "text": "2.2 Calculating Probabilities from the Normal Distribution\n\nSuppose \\(X \\sim \\mathcal{N}(0,1)\\), find the value \\(m\\) (green point) such that \\(P(X\\leq m)=0.95\\).\n\n\n\n\n\n\n\n\n\n\n\nGiven \\(X \\sim \\mathcal{N}(2,0.7^2)\\), find the probability of \\(X\\) being between 1 and 4.\nFind the probability \\(P(5\\leq X\\leq 12)\\) for \\(X \\sim \\mathcal{N}(10,5)\\)."
  },
  {
    "objectID": "lab_3_markdown.html#approximating-the-binomial-with-the-normal-distribution",
    "href": "lab_3_markdown.html#approximating-the-binomial-with-the-normal-distribution",
    "title": "ST117 Lab 3",
    "section": "2.3 Approximating the Binomial with the Normal distribution",
    "text": "2.3 Approximating the Binomial with the Normal distribution\n\nApproximate a Binomial distribution \\(Bin(20,0.5)\\) using a standard normally distributed \\(Z\\). Find the \\(z_1\\) and \\(z_2\\) such that \\(P(z_1\\leq Z\\leq z_2)\\) is the probability of getting between 5 and 10 heads.\n\n\n\n\n\n\nhint\n\n\n\nWe know that \\(Z\\sim\\mathcal{N}(0,1)\\), how do we linearly transform \\(Z\\) to match the mean and variance of a random variable from \\(Bin(20,0.5)\\)?\n\n\nUse R to calculate this probability using the standard normal distribution and check if it matches with Section 1(c)."
  },
  {
    "objectID": "lab_3_markdown.html#experiments",
    "href": "lab_3_markdown.html#experiments",
    "title": "ST117 Lab 3",
    "section": "3.1 Experiments",
    "text": "3.1 Experiments\n\nPlot \\(X\\) following a \\(\\text{Bin}(n,0.5)\\) for different values of \\(n=(3,10,25,100)\\). Also, plot the approximated normal distribution \\(Y \\sim \\mathcal{N}(np,npq)\\). We can observe how the normal distribution becomes a good approximation as n increases.\n\n\nsampleBin&lt;-function(n,p){\n  A&lt;-seq(-0.5,0.5+n)\n  x&lt;-0:n\n  binomial.pdf&lt;-dbinom(x,n,p)\n  tit&lt;-paste0(\"Histogram of X~Bin(\",n,\",\",p,\")\")\n  ymax&lt;-1.2*max(binomial.pdf)\n  mu&lt;-n*p\n  sigma&lt;-sqrt(n*p*(1-p))\n  y&lt;-seq(0,n,.1)\n  normal.pdf&lt;-dnorm(y,mu,sigma)\n  \n  plot(x,binomial.pdf,col=\"lightblue\",xlab = \"X\", ylab = \"P(X=x)\",main=tit, type=\"h\", \n       ylim = c(0,ymax),lwd=5)\n\n  lines(y,normal.pdf,type=\"l\",col=\"red\",lwd=2,lty=2)\n \n}\n\npar(mfrow=c(2,2))\nsampleBin(3,0.5)\nsampleBin(10,0.5)\nsampleBin(25,0.5)\nsampleBin(100,0.5)"
  },
  {
    "objectID": "lab_3_markdown.html#some-theory",
    "href": "lab_3_markdown.html#some-theory",
    "title": "ST117 Lab 3",
    "section": "3.2 Some theory",
    "text": "3.2 Some theory\n\nBinomial as a Sum of Bernoulli Trials\nThe Binomial distribution can be understood as the sum of independent and identically distributed Bernoulli trials. A Bernoulli trial is an experiment with exactly two possible outcomes: success (with probability \\(p\\)) and failure (with probability \\(1-p\\)). When we perform \\(n\\) such independent trials, the sum of successes follows a Binomial distribution, \\(\\text{Bin}(n, p)\\).\nMathematically, we have \\[\nX_\\text{Bin} = \\sum_{i =1}^n X_{\\text{Ber},i},\n\\]\nwhere \\(X_{\\text{Ber},i}\\sim^{i.i.d} \\operatorname{Bernoulli}(p)\\), and \\(X_\\text{Bin}\\sim \\text{Bin}(n, p)\\)\n\n\nCentral Limit Theorem\nThe Central Limit Theorem (CLT) states that, under certain conditions, the (normalised) sum of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the variables. In the context of the Binomial distribution, as the number of trials \\(n\\) becomes large, the distribution of the sum of the Bernoulli trials will tend towards a normal distribution.\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\nSuppose \\(X_1\\), \\(X_2\\), \\(\\dots\\) is a sequence of i.i.d. random variables with \\(\\mathbb{E}[X_1] = \\mu\\) and \\(\\operatorname{Var}[X_1] = \\sigma^2&lt;\\infty\\). Then, as \\(n\\) approaches infinity, the random variables \\(\\sqrt{n}(\\bar{X_n}-\\mu)\\) converges in distribution to a normal \\(\\mathcal{N(0,\\sigma^2)}\\):\n\\[\n\\sqrt{n}(\\bar{X_n}-\\mu) \\to \\mathcal{N(0,\\sigma^2)},\n\\] where \\(\\bar{X_n}=\\frac{1}{n}\\sum_{i=1}^n X_i\\)\n\n\n\n\nBoundary Conditions\nFor the convergence of a Binomial to a Normal distribution to be a good approximation, certain boundary conditions should be met:\n\nThe number of trials \\(n\\) should be large.\nNeither \\(p\\) nor \\(1-p\\) should be too small; a common rule of thumb is that both \\(np\\) and \\(n(1-p)\\) should be greater than 5.\n\nWhen these conditions are met, we can use the Normal distribution as an approximation for the Binomial distribution, greatly simplifying calculations in many cases.\n\\[\n\\text{Bin}(n, p) \\approx \\mathcal{N}(np, np(1-p))\n\\]\nThis approximation is particularly useful for calculating probabilities for large \\(n\\), where direct computation using the Binomial formula becomes impractical."
  },
  {
    "objectID": "lab_3_markdown.html#explorations",
    "href": "lab_3_markdown.html#explorations",
    "title": "ST117 Lab 3",
    "section": "3.3 Explorations",
    "text": "3.3 Explorations\nPlot \\(X\\) following a \\(\\text{Bin}(n,0.1)\\) for different values of \\(n=(3,10,25,100)\\). Check if the normal distribution is a good approximation.\n\nsampleBin&lt;-function(n,p){\n  A&lt;-seq(-0.5,0.5+n)\n  x&lt;-0:n\n  binomial.pdf&lt;-dbinom(x,n,p)\n  tit&lt;-paste0(\"Histogram of X~Bin(\",n,\",\",p,\")\")\n  ymax&lt;-1.2*max(binomial.pdf)\n  mu&lt;-n*p\n  sigma&lt;-sqrt(n*p*(1-p))\n  y&lt;-seq(0,n,.1)\n  normal.pdf&lt;-dnorm(y,mu,sigma)\n  \n  plot(x,binomial.pdf,col=\"lightblue\",xlab = \"X\", ylab = \"P(X=x)\",main=tit, type=\"h\", \n       ylim = c(0,ymax),lwd=5)\n\n  lines(y,normal.pdf,type=\"l\",col=\"red\",lwd=2,lty=2)\n \n\n}\n\npar(mfrow=c(2,2))\nsampleBin(3,0.1)\nsampleBin(10,0.1)\nsampleBin(25,0.1)\nsampleBin(100,0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nExplore the influence of \\(p\\) on convergence speed. Consider distribution like \\(Bin(100,0.1),\\ Bin(100,0.01),\\ Bin(10000,0.01)\\)."
  },
  {
    "objectID": "lab_2_markdown.html",
    "href": "lab_2_markdown.html",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "When we read a CSV file with read.csv, there is an argument header deciding whether it reads the first row as the column names of the variables.\nRecall that last time, we generated a random data frame of columns named “id” and “score” first.\n\ndata &lt;- data.frame(\n  id = 1:3,\n  score = sample(5:10, 3, replace = TRUE) # sample(list, n) allows you to sample number n values from list\n)\ndata\n\n  id score\n1  1     7\n2  2     7\n3  3     8\n\n\nNow, we write data into a CSV file\n\n# Write the data frame to a CSV file\nwrite.csv(data, \"sample_data.csv\", row.names = FALSE)\n\nIf we read with header=TRUE (default in this case), “id” and “score” are parsed as column names instead of variable values\n\ndata_read_header &lt;- read.csv(\"sample_data.csv\", header = TRUE)\ndata_read_header\n\n  id score\n1  1     7\n2  2     7\n3  3     8\n\n\nHowever, if we read with header=FALSE, then “id” and “score” are regarded as values\n\ndata_read_noheader &lt;- read.csv(\"sample_data.csv\", header = FALSE)\ndata_read_noheader\n\n  V1    V2\n1 id score\n2  1     7\n3  2     7\n4  3     8\n\n\nIn this case, you would run into problems if you simply take the first column of data_read:\n\ndata_read_noheader[,1]\n\n[1] \"id\" \"1\"  \"2\"  \"3\" \n\n\nYou also run into problems if you are getting a column by its name:\n\ndata_read_header$id\n\n[1] 1 2 3\n\n\n\ndata_read_noheader$id\n\nNULL\n\n\n\n\n\n\n\n\nNote\n\n\n\nheader is defaulted to TRUE if and only if the first row contains one fewer field than the number of columns. For further details, use ?read.csv to check the full documentation.\n\n\n\n\n\nThe R Console is an interactive platform for immediate execution of individual commands, ideal for exploratory data analysis and quick tests.\nIn contrast, R Scripts are non-interactive files where code can be written, saved, and executed in a structured and reproducible manner, suitable for complex and longer projects.\n\n\n\nWhen you find a useful R package that isn’t already installed on your system, you use install.packages() to download and install it. This is typically a one-time process for each package. For example, to install the ggplot2 package, you would use:\n\ninstall.packages(\"ggplot2\")\n\nEvery time you start a new R session and want to use a previously installed package, you need to load it using the library() function. This needs to be done at the beginning of your scripts to ensure that all functions from the package are available. For example:\n\nlibrary(ggplot2)\n\nThis command does not install the package again, but simply makes its functionality available in your current session.\n\n\n\nTo convert a string that represents a number into a numeric format, you can use the as.numeric() function. For example:\n\nnumbers_as_strings &lt;- c(\"1\", \"2\", \"3\")\nnumbers &lt;- as.numeric(numbers_as_strings)\n\nConversely, if you need to convert numbers to strings, perhaps for output formatting, use the as.character() function:\n\nnumbers &lt;- c(1, 2, 3)\nnumbers_as_strings &lt;- as.character(numbers)"
  },
  {
    "objectID": "lab_2_markdown.html#data-frame-header",
    "href": "lab_2_markdown.html#data-frame-header",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "When we read a CSV file with read.csv, there is an argument header deciding whether it reads the first row as the column names of the variables.\nRecall that last time, we generated a random data frame of columns named “id” and “score” first.\n\ndata &lt;- data.frame(\n  id = 1:3,\n  score = sample(5:10, 3, replace = TRUE) # sample(list, n) allows you to sample number n values from list\n)\ndata\n\n  id score\n1  1     7\n2  2     7\n3  3     8\n\n\nNow, we write data into a CSV file\n\n# Write the data frame to a CSV file\nwrite.csv(data, \"sample_data.csv\", row.names = FALSE)\n\nIf we read with header=TRUE (default in this case), “id” and “score” are parsed as column names instead of variable values\n\ndata_read_header &lt;- read.csv(\"sample_data.csv\", header = TRUE)\ndata_read_header\n\n  id score\n1  1     7\n2  2     7\n3  3     8\n\n\nHowever, if we read with header=FALSE, then “id” and “score” are regarded as values\n\ndata_read_noheader &lt;- read.csv(\"sample_data.csv\", header = FALSE)\ndata_read_noheader\n\n  V1    V2\n1 id score\n2  1     7\n3  2     7\n4  3     8\n\n\nIn this case, you would run into problems if you simply take the first column of data_read:\n\ndata_read_noheader[,1]\n\n[1] \"id\" \"1\"  \"2\"  \"3\" \n\n\nYou also run into problems if you are getting a column by its name:\n\ndata_read_header$id\n\n[1] 1 2 3\n\n\n\ndata_read_noheader$id\n\nNULL\n\n\n\n\n\n\n\n\nNote\n\n\n\nheader is defaulted to TRUE if and only if the first row contains one fewer field than the number of columns. For further details, use ?read.csv to check the full documentation."
  },
  {
    "objectID": "lab_2_markdown.html#r-script-vs-console",
    "href": "lab_2_markdown.html#r-script-vs-console",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "The R Console is an interactive platform for immediate execution of individual commands, ideal for exploratory data analysis and quick tests.\nIn contrast, R Scripts are non-interactive files where code can be written, saved, and executed in a structured and reproducible manner, suitable for complex and longer projects."
  },
  {
    "objectID": "lab_2_markdown.html#installing-and-loading-packages",
    "href": "lab_2_markdown.html#installing-and-loading-packages",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "When you find a useful R package that isn’t already installed on your system, you use install.packages() to download and install it. This is typically a one-time process for each package. For example, to install the ggplot2 package, you would use:\n\ninstall.packages(\"ggplot2\")\n\nEvery time you start a new R session and want to use a previously installed package, you need to load it using the library() function. This needs to be done at the beginning of your scripts to ensure that all functions from the package are available. For example:\n\nlibrary(ggplot2)\n\nThis command does not install the package again, but simply makes its functionality available in your current session."
  },
  {
    "objectID": "lab_2_markdown.html#converting-between-strings-and-mumbers",
    "href": "lab_2_markdown.html#converting-between-strings-and-mumbers",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "To convert a string that represents a number into a numeric format, you can use the as.numeric() function. For example:\n\nnumbers_as_strings &lt;- c(\"1\", \"2\", \"3\")\nnumbers &lt;- as.numeric(numbers_as_strings)\n\nConversely, if you need to convert numbers to strings, perhaps for output formatting, use the as.character() function:\n\nnumbers &lt;- c(1, 2, 3)\nnumbers_as_strings &lt;- as.character(numbers)"
  },
  {
    "objectID": "lab_2_markdown.html#random-numbers-and-data-frame",
    "href": "lab_2_markdown.html#random-numbers-and-data-frame",
    "title": "ST117 Lab 2",
    "section": "3.1 Random numbers and data frame",
    "text": "3.1 Random numbers and data frame\n\n3.1.1 Generating Random Numbers and Names\n(i) Generate two vectors \\((v_1,v_2)\\) of 30 random integers each, where the elements in \\(v_1\\) are uniformly drawn from \\(\\{80,81,\\dots,100\\}\\), and the elements in \\(v_2\\) are uniformly drawn from \\(\\{60,61,\\dots, 90 \\}\\), with replacement.\n\n\n\n\n\n\nsolution\n\n\n\n\nv1 &lt;- sample(80:100, 30, replace = TRUE)\nv2 &lt;- sample(60:90, 30, replace = TRUE)\n\n\n\n(ii) Generate a vector of 30 random names using the randomNames() function. Remember to install the randomNames package and load it!\n\ninstall.packages(\"randomNames\")\nlibrary(\"randomNames\")\n\n\n\n\n\n\n\nHint\n\n\n\nset.seed() allows the code to be reproducible by setting a specific seed value. When a seed is set, the sequence generated remains deterministic.\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\nset.seed(21012024)\nnames &lt;- randomNames(30)\n\n\n\n\n\n3.1.2 Create a data frame\nWe aim to record the names, assignment marks, and exam marks of 30 students from course 1 in a table. Using the functions above, first generate these items randomly, then combine them into a data frame with three columns: “names”, “assignment”, and “exam”.\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1 &lt;- data.frame(\n  names = randomNames(30),\n  assignment = sample(80:100, 30, replace = TRUE), \n  exam = sample(60:90, 30, replace = TRUE))\n\n\n\n\n\n3.1.3 Deal with data frame\n(i) First, calculate the final marks for this course using the formula \\[\\text{Final mark} = 0.2\\times \\text{Assignment} + 0.8\\times \\text{Exam}\\] and add this information to a new column named finalMark.\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1$finalMark &lt;- (0.2*course1$assignment + 0.8*course1$exam)\n\n\n\n(ii) Can you find the student with the highest finalMark?\n\n\n\n\n\n\nHint\n\n\n\n\nYou may consider sorting your data frame in descending order by the values of finalMarks - look up the different between sort and order!\nAlternatively, you can use the arrange function in the dplyr package for this task (optional).\n\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1[order(course1$finalMark, decreasing = TRUE),][1,]\n\n          names assignment exam finalMark\n17 Hagen, Sally        100   90        92\n\n# alternatively\ncourse1[order(course1$finalMark, decreasing = TRUE)[1],]\n\n          names assignment exam finalMark\n17 Hagen, Sally        100   90        92\n\n\nUsing dplyr:\n\ninstall.packages(\"dplyr\")\nlibrary(\"dplyr\")\n\n\ncourse1 %&gt;% arrange(desc(finalMark)) %&gt;% head(1) # %&gt;% is a pipe, which takes the output of the expression on its left and passes it as the first argument to the function on its right\n\n         names assignment exam finalMark\n1 Hagen, Sally        100   90        92\n\n\n\n\n(iii) Next, calculate the means of assignment, exam, and finalMarks, respectively.\n\n\n\n\n\n\nsolution\n\n\n\n\nround(mean(course1$assignment))\n\n[1] 91\n\nround(mean(course1$exam))\n\n[1] 76\n\nround(mean(course1$finalMark))\n\n[1] 79\n\n\n\nround(apply(X = course1[,2:4], MARGIN = 2, FUN = mean))\n\nassignment       exam  finalMark \n        91         76         79 \n\n\n\ncourse1 %&gt;%\n  summarize(across(c(2,3,4),mean)) %&gt;% round()\n\n  assignment exam finalMark\n1         91   76        79\n\n\n\n\n(iv) Then, randomly pick 10 students and set then to have chosen course 2. The other students have not chosen this course. Please add a column course2 to indicate their choice (0 for yes,1 for no).\n\n\n\n\n\n\nsolution\n\n\n\n\nrandom_numbers&lt;-sample(1:30,10,replace = FALSE)\ncourse1$course2&lt;- 0\ncourse1[c(random_numbers),]$course2&lt;-1\n\n\n\n(v) Finally, find the students with marks above 85 and who haven’t chosen course 2 by extracting values from the names column. You can also use the apply() function for this purpose. Verify if these two methods give the same results.\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1[course1$finalMark&gt;85 & course1$course2==0,]$names\n\n[1] \"Mcdonald, Demetri\" \"Gonzalez, Marissa\" \"Hagen, Sally\"     \n[4] \"Aragon, Faustina\"  \"Dubus, Jesse\"      \"Ash, Richard\"     \n\n\n\ncheck&lt;-function(x){\n  value &lt;- x[1]&gt;85 & x[2]==0\n  return(value)\n}\n\nfilter&lt;-apply(X = course1[,c(4,5)], 1, FUN = check)\ncourse1[filter,]$names\n\n[1] \"Mcdonald, Demetri\" \"Gonzalez, Marissa\" \"Hagen, Sally\"     \n[4] \"Aragon, Faustina\"  \"Dubus, Jesse\"      \"Ash, Richard\""
  },
  {
    "objectID": "lab_2_markdown.html#define-a-function",
    "href": "lab_2_markdown.html#define-a-function",
    "title": "ST117 Lab 2",
    "section": "3.2 Define a function",
    "text": "3.2 Define a function\nRecall that the Fibonacci sequence is defined by recurrent relations:\n\\(F_0=0,\\ F_1=1,\\ F_n=F_{n-1}+F_{n-2}\\).\nDefine a function to produce the nth Fibonacci number with or without a loop.\n\n\n\n\n\n\nsolution\n\n\n\nfor loop\n\nfb&lt;-function(n){\n  f&lt;-c(0,1)\n  if (n&gt;1){\n  for (i in 2:n){\n    f[i+1] &lt;- f[i] + f[i-1]\n  }}\n  return(f[n+1])\n}\n\nwithout for loop\n\nfb&lt;-function(n){\n  if(n==0){\n    return(0)\n  }\n  if(n==1){\n    return(1)\n  }\n  fb(n-1)+fb(n-2) #iterate until we meet the boundary conditions\n}"
  },
  {
    "objectID": "lab_2_markdown.html#uniform-distribution-and-histogram",
    "href": "lab_2_markdown.html#uniform-distribution-and-histogram",
    "title": "ST117 Lab 2",
    "section": "3.3 Uniform distribution and histogram",
    "text": "3.3 Uniform distribution and histogram\nSimulate 1000 samples from a uniform distribution \\(X\\sim U[0,1]\\) and create a histogram of the generated sequence. Overlay the histogram on the probability density function - does the histogram reflect the density well?\n\n\n\n\n\n\nHint\n\n\n\n\nYou can look up dunif(), which defines the probability density function of a uniform distribution.\nTo plot the histogram, you can simply use the hist function - alternatively, you can try the ggplot2 package.\n\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\n# generate the samples\nnum_sample &lt;- 1000 # you can try different values of num_sample\nsample &lt;- runif(n=num_sample,min=0,max=1)\n\n\n# get 100 evenly spaced values between -0.25 and 1.25 to plot the probability density function of the uniform distribution\nx &lt;- seq(-0.25, 1.25, length.out=100)\n\n#plotting the histogram\ntitle &lt;- sprintf(\"Histogram of %d simulations from X~U(%d,%d)\", num_sample, 0, 1)\nhist(sample, main = title, xlim = c(-0.5, 1.5), xlab = \"x\", prob = TRUE,col=\"lightblue\", ylab=\"f (x)\")\nlines(x, dunif(x,min=0,max=1), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nWith ggplot2:\n\n# Load ggplot2 library\nlibrary(ggplot2)\n\n# Create a data frame for the samples\ndf &lt;- data.frame(sample)\n\n# Create the histogram and overlay the probability density function\nggplot(df, aes(x = sample)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 0.08, fill = \"lightblue\", colour = \"black\") + \n  # here (y = after_stat(density)) means that we map the y-axis aesthetic to the density of the data, rather than the count, which is the default.\n  stat_function(fun = dunif, xlim = c(-0.25, 1.25), args = list(min = 0, max = 1), colour = \"red\", linewidth = 1) +\n  labs(title = sprintf(\"Histogram of %d simulations from X~U(%d,%d)\", num_sample, 0, 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\n\nIf we increase the number of simulations, does the fit improve?"
  },
  {
    "objectID": "lab_2_markdown.html#problem-statement",
    "href": "lab_2_markdown.html#problem-statement",
    "title": "ST117 Lab 2",
    "section": "Problem Statement",
    "text": "Problem Statement\nA and B are tossing a fair coin. A wins if HHH appears first; B wins if HTH appears first. Who is more likely to win?"
  },
  {
    "objectID": "lab_2_markdown.html#simulation-code",
    "href": "lab_2_markdown.html#simulation-code",
    "title": "ST117 Lab 2",
    "section": "Simulation Code",
    "text": "Simulation Code\nWe can write some codes to simulate the game\n\nsimulate_coin_toss &lt;- function(sequence_a, sequence_b, num_simulations = 1000) {\n  wins_a &lt;- 0\n  wins_b &lt;- 0\n\n  # play the game num_simulations times\n  for (i in 1:num_simulations) {\n    \n    # keep tossing until there is a winner\n    coin_sequence &lt;- \"\"\n    while (!grepl(sequence_a, coin_sequence) && !grepl(sequence_b, coin_sequence)) {\n      coin_sequence &lt;- paste0(coin_sequence, sample(c(\"H\", \"T\"), 1, replace = TRUE))\n    }\n    \n    # record the winner\n    if (grepl(sequence_a, coin_sequence)) {\n      wins_a &lt;- wins_a + 1\n    } else {\n      wins_b &lt;- wins_b + 1\n    }\n  }\n\n  # use the number of wins to estimate the winning probability\n  prob_a_wins &lt;- wins_a / num_simulations\n  prob_b_wins &lt;- wins_b / num_simulations\n\n  return(c(prob_a_wins, prob_b_wins))\n}\n\n# Call the function\nsimulate_coin_toss(\"HHH\", \"HTH\")\n\n[1] 0.39 0.61\n\n\n\n\n\n\n\n\nYour turn\n\n\n\n\nCan you write some codes to estimate the expected number of tosses needed until a certain player gets a win?\nCan you prove your winning probabilities algebraically?\n\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\n# Function to calculate expected number of tosses\nexpected_tosses &lt;- function(sequence, num_simulations = 1000) {\n  toss_counts &lt;- numeric(num_simulations)\n\n  for (i in 1:num_simulations) {\n    coin_sequence &lt;- \"\"\n    toss_count &lt;- 0\n\n    while (!grepl(sequence, coin_sequence)) {\n      coin_sequence &lt;- paste0(coin_sequence, sample(c(\"H\", \"T\"), 1, replace = TRUE))\n      toss_count &lt;- toss_count + 1\n    }\n\n    toss_counts[i] &lt;- toss_count\n  }\n\n  mean(toss_counts)\n}\n\n# Calculate for sequences \"HHH\" and \"HTH\"\nexpected_tosses(\"HHH\")\n\n[1] 13.994\n\nexpected_tosses(\"HTH\")\n\n[1] 9.572"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website is created by Mengqi Chen at Department of Statistics, University of Warwick in term 2, 2024. It is put together with Quarto, which is an open-source scientific and technical publishing system designed to create dynamic and reproducible documents. The markdown files for the webpages can be found on my GitHub Repository for this courese.\nFor feedback on the lab sessions please fill out the anonymous feedback form. For corrections and comments on this site, please email me."
  },
  {
    "objectID": "lab_6_markdown.html",
    "href": "lab_6_markdown.html",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "\\(\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\), where \\(x_i\\) are the observed values.\n\n\n\n\\(\\hat{p} = \\frac{\\bar{x}}{n}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\theta} = \\bar{x}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\mu} = \\bar{x}\\) and \\(\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\).\n\n\n\n\n\nBias: \\(\\operatorname{Bias}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta})-\\theta\\)\nVariance: \\(\\operatorname{Var}(\\hat{\\theta})\\) Measures the dispersion of the estimator’s distribution.\nMean Squared Error (MSE): \\(\\operatorname{MSE}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta}-\\theta)^2 = \\operatorname{Bias}(\\hat{\\theta})^2 + \\operatorname{Var}(\\hat{\\theta})\\) The average squared difference between the estimated values and the actual value. MSE = Bias^2 + Variance.\nConsistency: An estimator is consistent if it converges in probability to the true parameter value as the sample size increases. For this course, you can check consistency by checking if \\(\\operatorname{MSE}(\\theta)\\to 0\\) as \\(n\\to\\infty\\).\n\n\n\n\nWe will find the MLE of a Poisson sample, plot the log-likelihood function, find its maximum, and compare with the theoretical value. Recall that the Possion distribution:\n\\[\nP(X=x)=\\exp^{-\\theta}\\frac{\\theta^x}{x!}\n\\]\n\n\n\n# Simulating a Poisson-distributed sample\nset.seed(123)\ntheta_true &lt;- 4\nn_samples &lt;- 10\nsample_data &lt;- rpois(n_samples, theta_true)\n\nsample_data\n\n [1] 3 6 3 6 7 1 4 7 4 4\n\n\n\n\n\nThe log-likelihood function for Possion distribution:\n\\[\n\\begin{align}\nl(\\theta;\\vec{x}) &= -n\\theta + \\ln{\\theta}\\cdot \\left(\\sum_{i=1}^n x_i\\right) - \\underbrace{\\ln \\left(\\prod_{i=1}^n x_i!\\right)}_{\\text{constant in }\\theta} \\\\\n\\end{align}\n\\]\n\nlog_likelihood &lt;- function(theta, data) {\n  sum(data)*log(theta)-length(data)*theta\n}\n\ntheta_seq &lt;- seq(1, 8, by = 0.1)\nll_values &lt;- sapply(theta_seq, log_likelihood, data = sample_data)\n\nplot(theta_seq, ll_values, type = \"l\", main = \"Log-Likelihood Function\", xlab = \"theta\", ylab = \"Log-Likelihood\")\n\nMLE &lt;- mean(sample_data)\nabline(v = MLE)\n\n\n\n\n\n\n\n\n\n\n\n\nopt1 &lt;-optimize(f=log_likelihood, data = sample_data, interval=c(0,7),maximum=TRUE) \n\noptimiser &lt;- opt1$maximum\n\ncat(\"The MLE for theta is:\", MLE, \"\\n\")\n\nThe MLE for theta is: 4.5 \n\ncat(\"The optimiser for the log-likelihood is\", optimiser, \"\\n\")\n\nThe optimiser for the log-likelihood is 4.499999"
  },
  {
    "objectID": "lab_6_markdown.html#mle-for-common-distributions",
    "href": "lab_6_markdown.html#mle-for-common-distributions",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "\\(\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\), where \\(x_i\\) are the observed values.\n\n\n\n\\(\\hat{p} = \\frac{\\bar{x}}{n}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\theta} = \\bar{x}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\mu} = \\bar{x}\\) and \\(\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\)."
  },
  {
    "objectID": "lab_6_markdown.html#criteria-for-comparing-estimators",
    "href": "lab_6_markdown.html#criteria-for-comparing-estimators",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "Bias: \\(\\operatorname{Bias}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta})-\\theta\\)\nVariance: \\(\\operatorname{Var}(\\hat{\\theta})\\) Measures the dispersion of the estimator’s distribution.\nMean Squared Error (MSE): \\(\\operatorname{MSE}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta}-\\theta)^2 = \\operatorname{Bias}(\\hat{\\theta})^2 + \\operatorname{Var}(\\hat{\\theta})\\) The average squared difference between the estimated values and the actual value. MSE = Bias^2 + Variance.\nConsistency: An estimator is consistent if it converges in probability to the true parameter value as the sample size increases. For this course, you can check consistency by checking if \\(\\operatorname{MSE}(\\theta)\\to 0\\) as \\(n\\to\\infty\\)."
  },
  {
    "objectID": "lab_6_markdown.html#example-mle-for-a-poisson-distribution",
    "href": "lab_6_markdown.html#example-mle-for-a-poisson-distribution",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "We will find the MLE of a Poisson sample, plot the log-likelihood function, find its maximum, and compare with the theoretical value. Recall that the Possion distribution:\n\\[\nP(X=x)=\\exp^{-\\theta}\\frac{\\theta^x}{x!}\n\\]\n\n\n\n# Simulating a Poisson-distributed sample\nset.seed(123)\ntheta_true &lt;- 4\nn_samples &lt;- 10\nsample_data &lt;- rpois(n_samples, theta_true)\n\nsample_data\n\n [1] 3 6 3 6 7 1 4 7 4 4\n\n\n\n\n\nThe log-likelihood function for Possion distribution:\n\\[\n\\begin{align}\nl(\\theta;\\vec{x}) &= -n\\theta + \\ln{\\theta}\\cdot \\left(\\sum_{i=1}^n x_i\\right) - \\underbrace{\\ln \\left(\\prod_{i=1}^n x_i!\\right)}_{\\text{constant in }\\theta} \\\\\n\\end{align}\n\\]\n\nlog_likelihood &lt;- function(theta, data) {\n  sum(data)*log(theta)-length(data)*theta\n}\n\ntheta_seq &lt;- seq(1, 8, by = 0.1)\nll_values &lt;- sapply(theta_seq, log_likelihood, data = sample_data)\n\nplot(theta_seq, ll_values, type = \"l\", main = \"Log-Likelihood Function\", xlab = \"theta\", ylab = \"Log-Likelihood\")\n\nMLE &lt;- mean(sample_data)\nabline(v = MLE)\n\n\n\n\n\n\n\n\n\n\n\n\nopt1 &lt;-optimize(f=log_likelihood, data = sample_data, interval=c(0,7),maximum=TRUE) \n\noptimiser &lt;- opt1$maximum\n\ncat(\"The MLE for theta is:\", MLE, \"\\n\")\n\nThe MLE for theta is: 4.5 \n\ncat(\"The optimiser for the log-likelihood is\", optimiser, \"\\n\")\n\nThe optimiser for the log-likelihood is 4.499999"
  },
  {
    "objectID": "lab_6_markdown.html#bernoulli-distribution-1",
    "href": "lab_6_markdown.html#bernoulli-distribution-1",
    "title": "ST117 Lab 6",
    "section": "1. Bernoulli Distribution",
    "text": "1. Bernoulli Distribution\nSuppose we observe data \\(\\vec{x}=(1,0,0,1,0,1,0,0,1,1)\\) where each element \\(X_i\\) follows a Bernoulli distribution with an unknown success probability \\(p\\).\n\nFind the likelihood function \\(L(p;\\vec{x})\\) which represents the joint pdf function of \\(p\\) given the observed data \\(\\vec{x}\\) and define it as a function in R. Calculate the value of this function at \\(p=0.1\\).\nPlot the likelihood function for \\(p\\in[0,1]\\) and use the optimize() function to find the point that maximizes \\(L(p;\\vec{x})\\). Add a vertical line to the plot to indicate this maximum point.\nCalculate the log-likelihood function \\(l(p;\\vec{x})\\) and define this function in R. Plot the log-likelihood function. Verify that \\(p=0.5\\) maximizes the log-likelihood function by setting its first derivative equal to zero and ensuring that the second derivative is negative."
  },
  {
    "objectID": "lab_6_markdown.html#binomial-distribution-1",
    "href": "lab_6_markdown.html#binomial-distribution-1",
    "title": "ST117 Lab 6",
    "section": "2. Binomial Distribution",
    "text": "2. Binomial Distribution\nGiven that \\(X \\sim \\text{Bin}(n,p)\\) and observed that \\(n=10\\) and \\(x=3\\).\n\nDefine the likelihood function in R and calculate it at \\(p=0.1\\).\nPlot the likelihood function for \\(p\\in[0,1]\\) and calculate the maximum likelihood estimate. Add a vertical line to the plot to indicate this maximum point."
  },
  {
    "objectID": "lab_6_markdown.html#normal-distribution-1",
    "href": "lab_6_markdown.html#normal-distribution-1",
    "title": "ST117 Lab 6",
    "section": "3. Normal Distribution",
    "text": "3. Normal Distribution\nGiven the heights(in cm) of a random sample of 20 students:\n182, 154, 147, 150, 164, 177, 169, 173, 160, 173, 170, 160, 178, 175, 154, 179, 168, 188, 172, 162\nWe assume that the heights of students follow a normal distribution with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\n\nDetermine the maximum likelihood estimates of \\(\\mu\\) and \\(\\sigma\\) based on the given sample.\nCalculate the log-likelihood of these height estimates."
  }
]