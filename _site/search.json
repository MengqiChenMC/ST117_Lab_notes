[
  {
    "objectID": "lab_6_workbook.html",
    "href": "lab_6_workbook.html",
    "title": "ST117 Lab 6 Workbook",
    "section": "",
    "text": "Suppose we observe data \\(\\vec{x}=(1,0,0,1,0,1,0,0,1,1)\\) where each element \\(X_i\\) follows a Bernoulli distribution with an unknown success probability \\(p\\).\n\nFind the likelihood function \\(L(p;\\vec{x})\\) which represents the joint pdf function of \\(p\\) given the observed data \\(\\vec{x}\\) and define it as a function in R. Calculate the value of this function at \\(p=0.1\\).\n\n\n#TODO: write your codes here\n\n\nPlot the likelihood function for \\(p\\in[0,1]\\) and use the optimize() function to find the point that maximizes \\(L(p;\\vec{x})\\). Add a vertical line to the plot to indicate this maximum point.\n\n\n#TODO: write your codes here\n\n\nCalculate the log-likelihood function \\(l(p;\\vec{x})\\) and define this function in R. Plot the log-likelihood function. Verify that \\(p=0.5\\) maximizes the log-likelihood function by setting its first derivative equal to zero and ensuring that the second derivative is negative.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_workbook.html#bernoulli-distribution",
    "href": "lab_6_workbook.html#bernoulli-distribution",
    "title": "ST117 Lab 6 Workbook",
    "section": "",
    "text": "Suppose we observe data \\(\\vec{x}=(1,0,0,1,0,1,0,0,1,1)\\) where each element \\(X_i\\) follows a Bernoulli distribution with an unknown success probability \\(p\\).\n\nFind the likelihood function \\(L(p;\\vec{x})\\) which represents the joint pdf function of \\(p\\) given the observed data \\(\\vec{x}\\) and define it as a function in R. Calculate the value of this function at \\(p=0.1\\).\n\n\n#TODO: write your codes here\n\n\nPlot the likelihood function for \\(p\\in[0,1]\\) and use the optimize() function to find the point that maximizes \\(L(p;\\vec{x})\\). Add a vertical line to the plot to indicate this maximum point.\n\n\n#TODO: write your codes here\n\n\nCalculate the log-likelihood function \\(l(p;\\vec{x})\\) and define this function in R. Plot the log-likelihood function. Verify that \\(p=0.5\\) maximizes the log-likelihood function by setting its first derivative equal to zero and ensuring that the second derivative is negative.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_workbook.html#binomial-distribution",
    "href": "lab_6_workbook.html#binomial-distribution",
    "title": "ST117 Lab 6 Workbook",
    "section": "2. Binomial Distribution",
    "text": "2. Binomial Distribution\nGiven that \\(X \\sim \\text{Bin}(n,p)\\) and observed that \\(n=10\\) and \\(x=3\\).\n\nDefine the likelihood function in R and calculate it at \\(p=0.1\\).\n\n\n#TODO: write your codes here\n\n\nPlot the likelihood function for \\(p\\in[0,1]\\) and calculate the maximum likelihood estimate. Add a vertical line to the plot to indicate this maximum point.\n\n\n#TODO: write your codes here\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_workbook.html#normal-distribution",
    "href": "lab_6_workbook.html#normal-distribution",
    "title": "ST117 Lab 6 Workbook",
    "section": "3. Normal Distribution",
    "text": "3. Normal Distribution\nGiven the heights(in cm) of a random sample of 20 students:\n182, 154, 147, 150, 164, 177, 169, 173, 160, 173, 170, 160, 178, 175, 154, 179, 168, 188, 172, 162\nWe assume that the heights of students follow a normal distribution with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\n\nDetermine the maximum likelihood estimates of \\(\\mu\\) and \\(\\sigma\\) based on the given sample.\n\n\n#TODO: write your codes here\n\n\nCalculate the log-likelihood of these height estimates.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_6_markdown.html",
    "href": "lab_6_markdown.html",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "\\(\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\), where \\(x_i\\) are the observed values.\n\n\n\n\\(\\hat{p} = \\frac{\\bar{x}}{n}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\theta} = \\bar{x}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\mu} = \\bar{x}\\) and \\(\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\).\n\n\n\n\n\nBias: \\(\\operatorname{Bias}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta})-\\theta\\)\nVariance: \\(\\operatorname{Var}(\\hat{\\theta})\\) Measures the dispersion of the estimator’s distribution.\nMean Squared Error (MSE): \\(\\operatorname{MSE}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta}-\\theta)^2 = \\operatorname{Bias}(\\hat{\\theta})^2 + \\operatorname{Var}(\\hat{\\theta})\\) The average squared difference between the estimated values and the actual value. MSE = Bias^2 + Variance.\nConsistency: An estimator is consistent if it converges in probability to the true parameter value as the sample size increases. For this course, you can check consistency by checking if \\(\\operatorname{MSE}(\\theta)\\to 0\\) as \\(n\\to\\infty\\).\n\n\n\n\nWe will find the MLE of a Poisson sample, plot the log-likelihood function, find its maximum, and compare with the theoretical value. Recall that the Possion distribution:\n\\[\nP(X=x)=\\exp^{-\\theta}\\frac{\\theta^x}{x!}\n\\]\n\n\n\n# Simulating a Poisson-distributed sample\nset.seed(123)\ntheta_true &lt;- 4\nn_samples &lt;- 10\nsample_data &lt;- rpois(n_samples, theta_true)\n\nsample_data\n\n [1] 3 6 3 6 7 1 4 7 4 4\n\n\n\n\n\nThe log-likelihood function for Possion distribution:\n\\[\n\\begin{align}\nl(\\theta;\\vec{x}) &= -n\\theta + \\ln{\\theta}\\cdot \\left(\\sum_{i=1}^n x_i\\right) - \\underbrace{\\ln \\left(\\prod_{i=1}^n x_i!\\right)}_{\\text{constant in }\\theta} \\\\\n\\end{align}\n\\]\n\nlog_likelihood &lt;- function(theta, data) {\n  sum(data)*log(theta)-length(data)*theta\n}\n\ntheta_seq &lt;- seq(1, 8, by = 0.1)\nll_values &lt;- sapply(theta_seq, log_likelihood, data = sample_data)\n\nplot(theta_seq, ll_values, type = \"l\", main = \"Log-Likelihood Function\", xlab = \"theta\", ylab = \"Log-Likelihood\")\n\nMLE &lt;- mean(sample_data)\nabline(v = MLE)\n\n\n\n\n\n\n\n\n\n\n\n\nopt1 &lt;-optimize(f=log_likelihood, data = sample_data, interval=c(0,7),maximum=TRUE) \n\noptimiser &lt;- opt1$maximum\n\ncat(\"The MLE for theta is:\", MLE, \"\\n\")\n\nThe MLE for theta is: 4.5 \n\ncat(\"The optimiser for the log-likelihood is\", optimiser, \"\\n\")\n\nThe optimiser for the log-likelihood is 4.499999"
  },
  {
    "objectID": "lab_6_markdown.html#mle-for-common-distributions",
    "href": "lab_6_markdown.html#mle-for-common-distributions",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "\\(\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\), where \\(x_i\\) are the observed values.\n\n\n\n\\(\\hat{p} = \\frac{\\bar{x}}{n}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\theta} = \\bar{x}\\), where \\(\\bar{x}\\) is the sample mean.\n\n\n\n\\(\\hat{\\mu} = \\bar{x}\\) and \\(\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\)."
  },
  {
    "objectID": "lab_6_markdown.html#criteria-for-comparing-estimators",
    "href": "lab_6_markdown.html#criteria-for-comparing-estimators",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "Bias: \\(\\operatorname{Bias}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta})-\\theta\\)\nVariance: \\(\\operatorname{Var}(\\hat{\\theta})\\) Measures the dispersion of the estimator’s distribution.\nMean Squared Error (MSE): \\(\\operatorname{MSE}(\\hat{\\theta}) = \\mathbb{E}(\\hat{\\theta}-\\theta)^2 = \\operatorname{Bias}(\\hat{\\theta})^2 + \\operatorname{Var}(\\hat{\\theta})\\) The average squared difference between the estimated values and the actual value. MSE = Bias^2 + Variance.\nConsistency: An estimator is consistent if it converges in probability to the true parameter value as the sample size increases. For this course, you can check consistency by checking if \\(\\operatorname{MSE}(\\theta)\\to 0\\) as \\(n\\to\\infty\\)."
  },
  {
    "objectID": "lab_6_markdown.html#example-mle-for-a-poisson-distribution",
    "href": "lab_6_markdown.html#example-mle-for-a-poisson-distribution",
    "title": "ST117 Lab 6",
    "section": "",
    "text": "We will find the MLE of a Poisson sample, plot the log-likelihood function, find its maximum, and compare with the theoretical value. Recall that the Possion distribution:\n\\[\nP(X=x)=\\exp^{-\\theta}\\frac{\\theta^x}{x!}\n\\]\n\n\n\n# Simulating a Poisson-distributed sample\nset.seed(123)\ntheta_true &lt;- 4\nn_samples &lt;- 10\nsample_data &lt;- rpois(n_samples, theta_true)\n\nsample_data\n\n [1] 3 6 3 6 7 1 4 7 4 4\n\n\n\n\n\nThe log-likelihood function for Possion distribution:\n\\[\n\\begin{align}\nl(\\theta;\\vec{x}) &= -n\\theta + \\ln{\\theta}\\cdot \\left(\\sum_{i=1}^n x_i\\right) - \\underbrace{\\ln \\left(\\prod_{i=1}^n x_i!\\right)}_{\\text{constant in }\\theta} \\\\\n\\end{align}\n\\]\n\nlog_likelihood &lt;- function(theta, data) {\n  sum(data)*log(theta)-length(data)*theta\n}\n\ntheta_seq &lt;- seq(1, 8, by = 0.1)\nll_values &lt;- sapply(theta_seq, log_likelihood, data = sample_data)\n\nplot(theta_seq, ll_values, type = \"l\", main = \"Log-Likelihood Function\", xlab = \"theta\", ylab = \"Log-Likelihood\")\n\nMLE &lt;- mean(sample_data)\nabline(v = MLE)\n\n\n\n\n\n\n\n\n\n\n\n\nopt1 &lt;-optimize(f=log_likelihood, data = sample_data, interval=c(0,7),maximum=TRUE) \n\noptimiser &lt;- opt1$maximum\n\ncat(\"The MLE for theta is:\", MLE, \"\\n\")\n\nThe MLE for theta is: 4.5 \n\ncat(\"The optimiser for the log-likelihood is\", optimiser, \"\\n\")\n\nThe optimiser for the log-likelihood is 4.499999"
  },
  {
    "objectID": "lab_6_markdown.html#bernoulli-distribution-1",
    "href": "lab_6_markdown.html#bernoulli-distribution-1",
    "title": "ST117 Lab 6",
    "section": "1. Bernoulli Distribution",
    "text": "1. Bernoulli Distribution\nSuppose we observe data \\(\\vec{x}=(1,0,0,1,0,1,0,0,1,1)\\) where each element \\(X_i\\) follows a Bernoulli distribution with an unknown success probability \\(p\\).\n\nFind the likelihood function \\(L(p;\\vec{x})\\) which represents the joint pdf function of \\(p\\) given the observed data \\(\\vec{x}\\) and define it as a function in R. Calculate the value of this function at \\(p=0.1\\).\nPlot the likelihood function for \\(p\\in[0,1]\\) and use the optimize() function to find the point that maximizes \\(L(p;\\vec{x})\\). Add a vertical line to the plot to indicate this maximum point.\nCalculate the log-likelihood function \\(l(p;\\vec{x})\\) and define this function in R. Plot the log-likelihood function. Verify that \\(p=0.5\\) maximizes the log-likelihood function by setting its first derivative equal to zero and ensuring that the second derivative is negative."
  },
  {
    "objectID": "lab_6_markdown.html#binomial-distribution-1",
    "href": "lab_6_markdown.html#binomial-distribution-1",
    "title": "ST117 Lab 6",
    "section": "2. Binomial Distribution",
    "text": "2. Binomial Distribution\nGiven that \\(X \\sim \\text{Bin}(n,p)\\) and observed that \\(n=10\\) and \\(x=3\\).\n\nDefine the likelihood function in R and calculate it at \\(p=0.1\\).\nPlot the likelihood function for \\(p\\in[0,1]\\) and calculate the maximum likelihood estimate. Add a vertical line to the plot to indicate this maximum point."
  },
  {
    "objectID": "lab_6_markdown.html#normal-distribution-1",
    "href": "lab_6_markdown.html#normal-distribution-1",
    "title": "ST117 Lab 6",
    "section": "3. Normal Distribution",
    "text": "3. Normal Distribution\nGiven the heights(in cm) of a random sample of 20 students:\n182, 154, 147, 150, 164, 177, 169, 173, 160, 173, 170, 160, 178, 175, 154, 179, 168, 188, 172, 162\nWe assume that the heights of students follow a normal distribution with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\n\nDetermine the maximum likelihood estimates of \\(\\mu\\) and \\(\\sigma\\) based on the given sample.\nCalculate the log-likelihood of these height estimates."
  },
  {
    "objectID": "lab_7_markdown.html",
    "href": "lab_7_markdown.html",
    "title": "ST117 Lab 7",
    "section": "",
    "text": "Linear regression is a fundamental statistical and machine learning method that models the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables) using a linear function:\n\\[\nY = a + bX + \\varepsilon, \\quad \\mathbb{E}(\\varepsilon) = 0.\n\\]\n\n\nTo understand linear regression, it’s helpful to start by simulating some data that follows a linear model. In R, we can simulate data using the following approach:\n\n# Set the seed for reproducibility\nset.seed(123)\n\n# Simulate data\nn &lt;- 100 # number of observations\nx &lt;- seq(0,10,10/n) # explanatory variable\na &lt;- 2 # intercept\nb &lt;- 0.5 # slope\nsigma &lt;- 1 # standard deviation of errors\n\n# Generate response variable\ny &lt;- a + b * x + rnorm(n, mean = 0, sd = sigma)\n\nWarning in a + b * x + rnorm(n, mean = 0, sd = sigma): longer object length is\nnot a multiple of shorter object length\n\n# Plot\nplot(x, y, main = \"Simulated Data for Linear Regression\", xlab = \"Explanatory Variable\", ylab = \"Response Variable\")\n\n\n\n\n\n\n\ndata &lt;- data.frame(x, y)\n\n\n\n\nThe relationship between the explanatory and response variables in linear regression can be quantified using the sample covariance and correlation. The formulae for these estimators are as follows:\n\nSample Covariance: \\[\ncov(X, Y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})\n\\]\nSample Correlation: \\[\ncorr(X, Y) = \\frac{cov(X, Y)}{s_X s_Y}\n\\] where \\(s_X\\) and \\(s_Y\\) are the sample standard deviations of \\(X\\) and \\(Y\\), respectively.\n\nNow, let’s calculate the sample covariance and correlation for our generated data x and y:\n\n# Calculate means of x and y\nmean_x &lt;- mean(x)\nmean_y &lt;- mean(y)\n\n# Calculate sample covariance\ncov_x_y_manual &lt;- sum((x - mean_x) * (y - mean_y)) / (n - 1)\n\n# Calculate sample correlation\ncorr_x_y_manual &lt;- cov_x_y_manual / (sd(x) * sd(y))\ncat(\"Manually Calculated Sample Covariance: \", cov_x_y_manual, \"\\n\")\n\nManually Calculated Sample Covariance:  4.514335 \n\ncat(\"Manually Calculated Sample Correlation: \", corr_x_y_manual, \"\\n\")\n\nManually Calculated Sample Correlation:  0.8678167 \n\n\nAlternatively, just use the cov and cor functions.\n\n# Calculate sample covariance\ncov_x_y &lt;- cov(x, y)\n# Calculate sample correlation\ncorr_x_y &lt;- cor(x, y)\ncat(\"Sample Covariance: \", cov_x_y, \"\\n\")\n\nSample Covariance:  4.469192 \n\ncat(\"Sample Correlation: \", corr_x_y, \"\\n\")\n\nSample Correlation:  0.8591386 \n\n\nThese estimators can be used to compute the slope (\\(\\hat{b}\\)) and intercept (\\(\\hat{a}\\)) of the linear regression model:\n\\[\n\\hat{b} = \\frac{cov(X, Y)}{var(X)}, \\quad \\hat{a} = \\bar{Y} - \\hat{b}\\bar{X}\n\\]\n\n\n\nR provides the lm function for fitting linear models. It simplifies the process of fitting a model to the data and making predictions. Here’s how to use it:\n\n# Fit linear model\nmodel &lt;- lm(y ~ x, data = data)\n\n# Summary of the model\nprint(model)\n\n\nCall:\nlm(formula = y ~ x, data = data)\n\nCoefficients:\n(Intercept)            x  \n     1.9811       0.5206  \n\n# Plot with regression line\nplot(x, y, main = \"Linear Regression with lm Function\", xlab = \"Explanatory Variable\", ylab = \"Response Variable\")\nabline(model, col = \"red\")\n\n\n\n\n\n\n\n\nThe lm function automatically computes the best-fitting line through the data by minimising the sum of squared residuals. The summary function provides detailed information about the model, including the coefficients, their standard errors, and statistical significance."
  },
  {
    "objectID": "lab_7_markdown.html#simulating-data-for-linear-regression",
    "href": "lab_7_markdown.html#simulating-data-for-linear-regression",
    "title": "ST117 Lab 7",
    "section": "",
    "text": "To understand linear regression, it’s helpful to start by simulating some data that follows a linear model. In R, we can simulate data using the following approach:\n\n# Set the seed for reproducibility\nset.seed(123)\n\n# Simulate data\nn &lt;- 100 # number of observations\nx &lt;- seq(0,10,10/n) # explanatory variable\na &lt;- 2 # intercept\nb &lt;- 0.5 # slope\nsigma &lt;- 1 # standard deviation of errors\n\n# Generate response variable\ny &lt;- a + b * x + rnorm(n, mean = 0, sd = sigma)\n\nWarning in a + b * x + rnorm(n, mean = 0, sd = sigma): longer object length is\nnot a multiple of shorter object length\n\n# Plot\nplot(x, y, main = \"Simulated Data for Linear Regression\", xlab = \"Explanatory Variable\", ylab = \"Response Variable\")\n\n\n\n\n\n\n\ndata &lt;- data.frame(x, y)"
  },
  {
    "objectID": "lab_7_markdown.html#calculating-sample-covariance-and-correlation-estimators",
    "href": "lab_7_markdown.html#calculating-sample-covariance-and-correlation-estimators",
    "title": "ST117 Lab 7",
    "section": "",
    "text": "The relationship between the explanatory and response variables in linear regression can be quantified using the sample covariance and correlation. The formulae for these estimators are as follows:\n\nSample Covariance: \\[\ncov(X, Y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})\n\\]\nSample Correlation: \\[\ncorr(X, Y) = \\frac{cov(X, Y)}{s_X s_Y}\n\\] where \\(s_X\\) and \\(s_Y\\) are the sample standard deviations of \\(X\\) and \\(Y\\), respectively.\n\nNow, let’s calculate the sample covariance and correlation for our generated data x and y:\n\n# Calculate means of x and y\nmean_x &lt;- mean(x)\nmean_y &lt;- mean(y)\n\n# Calculate sample covariance\ncov_x_y_manual &lt;- sum((x - mean_x) * (y - mean_y)) / (n - 1)\n\n# Calculate sample correlation\ncorr_x_y_manual &lt;- cov_x_y_manual / (sd(x) * sd(y))\ncat(\"Manually Calculated Sample Covariance: \", cov_x_y_manual, \"\\n\")\n\nManually Calculated Sample Covariance:  4.514335 \n\ncat(\"Manually Calculated Sample Correlation: \", corr_x_y_manual, \"\\n\")\n\nManually Calculated Sample Correlation:  0.8678167 \n\n\nAlternatively, just use the cov and cor functions.\n\n# Calculate sample covariance\ncov_x_y &lt;- cov(x, y)\n# Calculate sample correlation\ncorr_x_y &lt;- cor(x, y)\ncat(\"Sample Covariance: \", cov_x_y, \"\\n\")\n\nSample Covariance:  4.469192 \n\ncat(\"Sample Correlation: \", corr_x_y, \"\\n\")\n\nSample Correlation:  0.8591386 \n\n\nThese estimators can be used to compute the slope (\\(\\hat{b}\\)) and intercept (\\(\\hat{a}\\)) of the linear regression model:\n\\[\n\\hat{b} = \\frac{cov(X, Y)}{var(X)}, \\quad \\hat{a} = \\bar{Y} - \\hat{b}\\bar{X}\n\\]"
  },
  {
    "objectID": "lab_7_markdown.html#using-the-lm-function-in-r",
    "href": "lab_7_markdown.html#using-the-lm-function-in-r",
    "title": "ST117 Lab 7",
    "section": "",
    "text": "R provides the lm function for fitting linear models. It simplifies the process of fitting a model to the data and making predictions. Here’s how to use it:\n\n# Fit linear model\nmodel &lt;- lm(y ~ x, data = data)\n\n# Summary of the model\nprint(model)\n\n\nCall:\nlm(formula = y ~ x, data = data)\n\nCoefficients:\n(Intercept)            x  \n     1.9811       0.5206  \n\n# Plot with regression line\nplot(x, y, main = \"Linear Regression with lm Function\", xlab = \"Explanatory Variable\", ylab = \"Response Variable\")\nabline(model, col = \"red\")\n\n\n\n\n\n\n\n\nThe lm function automatically computes the best-fitting line through the data by minimising the sum of squared residuals. The summary function provides detailed information about the model, including the coefficients, their standard errors, and statistical significance."
  },
  {
    "objectID": "lab_7_markdown.html#linear-regression-model",
    "href": "lab_7_markdown.html#linear-regression-model",
    "title": "ST117 Lab 7",
    "section": "1. Linear Regression Model",
    "text": "1. Linear Regression Model\nGenerate a sample from the linear regression model:\n\\[\nY_i = 2X_i + \\varepsilon, \\ \\varepsilon_i \\sim \\mathcal{N}(0,5)\n\\]\n\nFind the regression line to predict \\(\\hat{y}\\) by \\(x\\), i.e. find \\(\\hat{a}_1\\), \\(\\hat{b}_1\\) such that\n\n\\[\nY = \\hat{b}_1 X + \\hat{a} _1\n\\]\nmanually using the covraiance and correlation estimators. Then verify the values using the lm function in R.\n\nFind the regression line to predict \\(\\hat{x}\\) by \\(y\\), i.e. find \\(\\hat{a}_2\\), \\(\\hat{b}_2\\) such that\n\n\\[\nX = \\hat{b}_2 Y + \\hat{a}_2\n\\]\nmanually using the covraiance and correlation estimators. Then verify the values using the lm function in R.\n\nPlot the data along with the two regression lines. Which regression line appears to be better?\nThe Least Squared Estimation can also help us derive the estimates of \\(\\hat{a}\\) and \\(\\hat{b}\\). We just need to find the value of \\(a\\) and \\(b\\) that minimizes the following expression: \\[\n\\sum_{i=1}^{n} \\Big( y_i-(a+bx_i) \\Big)^2\n\\] Hint: Use the optim function."
  },
  {
    "objectID": "lab_7_markdown.html#mean-squared-error",
    "href": "lab_7_markdown.html#mean-squared-error",
    "title": "ST117 Lab 7",
    "section": "2. Mean Squared Error",
    "text": "2. Mean Squared Error\nConsider a random sample \\(X_1,X_2,\\ldots,X_n\\) from a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). We have the following two estimators of the population variance obtained from the given sample information. From our previous lab, we derived the Maximum Likelihood Estimator(MLE) of the population variance as: \\[\n1.\\ \\hat{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^{n}(X_i-\\overline{X})^2.\n\\] Additionally, we have the sample variance given by: \\[\n2.\\ s^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\overline{X})^2,\n\\] where \\(\\overline{X}\\) represents the sample mean.\n\nSimulate a sample of 10 data from \\(\\text{N}(160,10^2)\\). Calculate the values of these two estimators and their Mean Squared Error(MSE).\nTry sample sizes of 100, 1000 and 10000, and show the results in a table. Can you provide an interpretation?"
  },
  {
    "objectID": "activity1_template.html",
    "href": "activity1_template.html",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;This can be from an online source or a dataset you create manually. Describe the dataset briefly.&gt;\n\n\n\n&lt;Use R to load your dataset into a data frame. Show the code you used. You may use functions such as head() or glimpse(from dplyr) to display the data frame&gt;\n\n# Your R code to load (and display) the dataset \n\n\n\n\n&lt;Create a visualisation of the dataset. Consider the type of data and what you wish to convey.&gt;\n\n# Your R code for the visualisation\n\n\n\n\n&lt;Explain why you chose the type of plot, what it aims to show, and what insights it provides about the dataset’s context.&gt;"
  },
  {
    "objectID": "activity1_template.html#find-a-small-dataset",
    "href": "activity1_template.html#find-a-small-dataset",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;This can be from an online source or a dataset you create manually. Describe the dataset briefly.&gt;"
  },
  {
    "objectID": "activity1_template.html#load-the-dataset",
    "href": "activity1_template.html#load-the-dataset",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;Use R to load your dataset into a data frame. Show the code you used. You may use functions such as head() or glimpse(from dplyr) to display the data frame&gt;\n\n# Your R code to load (and display) the dataset"
  },
  {
    "objectID": "activity1_template.html#visualisation",
    "href": "activity1_template.html#visualisation",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;Create a visualisation of the dataset. Consider the type of data and what you wish to convey.&gt;\n\n# Your R code for the visualisation"
  },
  {
    "objectID": "activity1_template.html#explanation",
    "href": "activity1_template.html#explanation",
    "title": "Activity 1: Data visualisation",
    "section": "",
    "text": "&lt;Explain why you chose the type of plot, what it aims to show, and what insights it provides about the dataset’s context.&gt;"
  },
  {
    "objectID": "activity1_template.html#find-a-large-dataset",
    "href": "activity1_template.html#find-a-large-dataset",
    "title": "Activity 1: Data visualisation",
    "section": "2.1 Find a Large Dataset",
    "text": "2.1 Find a Large Dataset\n&lt;Look for a large dataset available online. Describe the dataset and its source.&gt;"
  },
  {
    "objectID": "activity1_template.html#load-the-dataset-1",
    "href": "activity1_template.html#load-the-dataset-1",
    "title": "Activity 1: Data visualisation",
    "section": "2.2 Load the Dataset",
    "text": "2.2 Load the Dataset\n&lt;Use R to load your dataset into a data frame. Show the code you used. You may use functions such as head() or glimpse(from dplyr) to display the data frame&gt;\n\n# Your R code to load (and display) the dataset"
  },
  {
    "objectID": "activity1_template.html#visualisation-1",
    "href": "activity1_template.html#visualisation-1",
    "title": "Activity 1: Data visualisation",
    "section": "2.3 Visualisation",
    "text": "2.3 Visualisation\n&lt;Create a visualisation that highlights key aspects of the dataset.&gt;\n\n# Your R code for the visualisation"
  },
  {
    "objectID": "activity1_template.html#explanation-1",
    "href": "activity1_template.html#explanation-1",
    "title": "Activity 1: Data visualisation",
    "section": "2.4 Explanation",
    "text": "2.4 Explanation\n&lt;Discuss your choice of visualisation, its relevance, and the insights it offers about the dataset.&gt;\n\n# Your written explanation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the website for the ST117 Introduction to Statistics Lab sessions. This site is regularly updated with lab notes for each session. Labs 5 and 8 are for student presentations, so there are no lab notes for these two sessions. It also contains a variety of resources to assist you in learning R and statistical modelling."
  },
  {
    "objectID": "index.html#useful-resources",
    "href": "index.html#useful-resources",
    "title": "Home",
    "section": "Useful Resources",
    "text": "Useful Resources\nThe following cheatsheets can be helpful for quick references:\n\nR Cheatsheet: A comprehensive guide to the basics of R programming.\nData-Wrangling Cheatsheet: A summary of various data-wrangling commands with packages dplyr and tidyr.\nggplot2 Cheatsheet: ggplot2 is a powerful tool for making custom plots in R. This cheatsheet provides a concise guide.\ntidyverse Cheatsheet: tdyverse is a collection of R packages designed for data science. This cheatsheet covers some of the most commonly used packages.\nR Markdown Cheatsheet: This cheatsheet provides a quick reference to the R Markdown syntax.\nStatistical Distributions Cheatsheet: A sheet summarising the properties of some basic discrete and continuous distributions.\nMathematics in R Markdown: This pages summarises common LaTex syntax for R markdown."
  },
  {
    "objectID": "index.html#lab-workbooks",
    "href": "index.html#lab-workbooks",
    "title": "Home",
    "section": "Lab workbooks",
    "text": "Lab workbooks\nHere are the links to the R Markdown workbooks:\nLab 3 Workbook · Lab 4 Workbook · Lab 6 Workbook · Lab 7 Workbook · Lab 9 Workbook"
  },
  {
    "objectID": "index.html#feedback",
    "href": "index.html#feedback",
    "title": "Home",
    "section": "Feedback",
    "text": "Feedback\nPlease fill out the anonymous feedback form to help make the lab sessions better for everyone!\nFaculty Feedback Form"
  },
  {
    "objectID": "lab_3_markdown.html",
    "href": "lab_3_markdown.html",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "This lab session aims to familiarize you with the use of R for basic statistical analysis. We will cover various distributions, their properties, and how to use R to work with these distributions.\n\n\n\n\n\n\n\n\n\n\n\nDistribution\nParameters\nSample Command\nDensity Function\nDistribution Function\nQuantile Function\n\n\n\n\nUniform\nmin, max\nrunif(n, min, max)\ndunif(x, min, max)\npunif(q, min, max)\nqunif(p, min, max)\n\n\nBinomial\nsize, prob\nrbinom(n, size, prob)\ndbinom(x, size, prob)\npbinom(q, size, prob)\nqbinom(p, size, prob)\n\n\nPoisson\nlambda\nrpois(n, lambda)\ndpois(x, lambda)\nppois(q, lambda)\nqpois(p, lambda)\n\n\nNormal\nmean, sd\nrnorm(n, mean, sd)\ndnorm(x, mean, sd)\npnorm(q, mean, sd)\nqnorm(p, mean, sd)\n\n\nGamma\nshape, rate\nrgamma(n, shape, rate)\ndgamma(x, shape, rate)\npgamma(q, shape, rate)\nqgamma(p, shape, rate)\n\n\nBeta\nshape1, shape2\nrbeta(n, shape1, shape2)\ndbeta(x, shape1, shape2)\npbeta(q, shape1, shape2)\nqbeta(p, shape1, shape2)\n\n\n\n\n\n\n# Drawing 200 samples from a binomial distribution\nsample_size &lt;- 200\nsize &lt;- 10\nprob &lt;- 0.7\nbinom_samples &lt;- rbinom(sample_size, size, prob)\n\n\n\n\nNext, let us plot the histogram of the samples.\n\n# Plotting histogram with density overlay\nhist(binom_samples, probability = TRUE, main = \"Samples from Bin(10,0.7)\", xlab = \"Values\", ylab = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nThe following code calculates the mean, variance, and standard deviation of the samples.\n\n# Calculating mean, variance, and standard deviation\nmean_value &lt;- mean(binom_samples)\nsprintf(\"mean = %s\", mean_value)\n\n[1] \"mean = 6.875\"\n\nvariance_value &lt;- var(binom_samples)\nsprintf(\"variance = %s\", variance_value)\n\n[1] \"variance = 2.18027638190955\"\n\nsd_value &lt;- sqrt(var(binom_samples))\nsprintf(\"standard deviation = %s\", sd_value)\n\n[1] \"standard deviation = 1.4765758977816\"\n\n\n\n\n\nRecall that we have \\(X \\sim \\operatorname{Bin}(10,0.7)\\).\n\nWhat is the probability \\(P(X = 6)\\)?\n\n\n# use \"d+dist\" to calculate the density at a point\np_6 &lt;- dbinom(6,10,0.7)\nsprintf(\"P(X=6) = %s\", p_6)\n\n[1] \"P(X=6) = 0.200120949\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen d+dist(\\(x\\)) is the density of \\(X\\) at \\(x\\), and \\(P(X=x)=0\\) for all \\(x\\).\n\n\n\nWhat is the probability \\(P(2\\leq X \\leq 5)\\)?\n\n\n# use \"p+dist\" to calculate P(X&lt;=a)\np_less_than_5 &lt;- pbinom(5,10,0.7)\np_less_than_1 &lt;- pbinom(1,10,0.7)\np_2to5 &lt;- p_less_than_5 - p_less_than_1\nsprintf(\"P(2&lt;=X&lt;=5) = %s\", p_2to5)\n\n[1] \"P(2&lt;=X&lt;=5) = 0.1501246467\"\n\n\n\nWhat is the smallest value of \\(a\\) such that \\(P(X\\leq a) \\geq 0.5\\)?\n\n\n# let's take a look at the distribution function first:\ndist_df = data.frame(\n  a = 0:10,\n  p_x_lessthan_a = pbinom(0:10,10,0.7)\n)\ndist_df\n\n    a p_x_lessthan_a\n1   0   0.0000059049\n2   1   0.0001436859\n3   2   0.0015903864\n4   3   0.0105920784\n5   4   0.0473489874\n6   5   0.1502683326\n7   6   0.3503892816\n8   7   0.6172172136\n9   8   0.8506916541\n10  9   0.9717524751\n11 10   1.0000000000\n\n\n\n# can use \"q+dist\" to find such a\nquantile &lt;- qbinom(0.5,10,0.7)\nsprintf(\"a = %s\", quantile)\n\n[1] \"a = 7\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen q+dist(\\(q\\)) is a one to one function giving precisely the \\(a\\) such that \\(P(X\\leq a)=q\\).\n\n\n\n\n\nWe have that if \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\), then \\(aX+b\\sim \\mathcal{N}(a\\mu+b,a^2\\sigma^2)\\). This property is useful when we want to transform a standard \\(\\mathcal{N}(0,1)\\) to match a given set of mean and variance."
  },
  {
    "objectID": "lab_3_markdown.html#drawing-samples-from-a-given-distribution",
    "href": "lab_3_markdown.html#drawing-samples-from-a-given-distribution",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "# Drawing 200 samples from a binomial distribution\nsample_size &lt;- 200\nsize &lt;- 10\nprob &lt;- 0.7\nbinom_samples &lt;- rbinom(sample_size, size, prob)"
  },
  {
    "objectID": "lab_3_markdown.html#histogram",
    "href": "lab_3_markdown.html#histogram",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "Next, let us plot the histogram of the samples.\n\n# Plotting histogram with density overlay\nhist(binom_samples, probability = TRUE, main = \"Samples from Bin(10,0.7)\", xlab = \"Values\", ylab = \"Density\")"
  },
  {
    "objectID": "lab_3_markdown.html#mean-and-variance",
    "href": "lab_3_markdown.html#mean-and-variance",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "The following code calculates the mean, variance, and standard deviation of the samples.\n\n# Calculating mean, variance, and standard deviation\nmean_value &lt;- mean(binom_samples)\nsprintf(\"mean = %s\", mean_value)\n\n[1] \"mean = 6.875\"\n\nvariance_value &lt;- var(binom_samples)\nsprintf(\"variance = %s\", variance_value)\n\n[1] \"variance = 2.18027638190955\"\n\nsd_value &lt;- sqrt(var(binom_samples))\nsprintf(\"standard deviation = %s\", sd_value)\n\n[1] \"standard deviation = 1.4765758977816\""
  },
  {
    "objectID": "lab_3_markdown.html#probability-and-quantiles",
    "href": "lab_3_markdown.html#probability-and-quantiles",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "Recall that we have \\(X \\sim \\operatorname{Bin}(10,0.7)\\).\n\nWhat is the probability \\(P(X = 6)\\)?\n\n\n# use \"d+dist\" to calculate the density at a point\np_6 &lt;- dbinom(6,10,0.7)\nsprintf(\"P(X=6) = %s\", p_6)\n\n[1] \"P(X=6) = 0.200120949\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen d+dist(\\(x\\)) is the density of \\(X\\) at \\(x\\), and \\(P(X=x)=0\\) for all \\(x\\).\n\n\n\nWhat is the probability \\(P(2\\leq X \\leq 5)\\)?\n\n\n# use \"p+dist\" to calculate P(X&lt;=a)\np_less_than_5 &lt;- pbinom(5,10,0.7)\np_less_than_1 &lt;- pbinom(1,10,0.7)\np_2to5 &lt;- p_less_than_5 - p_less_than_1\nsprintf(\"P(2&lt;=X&lt;=5) = %s\", p_2to5)\n\n[1] \"P(2&lt;=X&lt;=5) = 0.1501246467\"\n\n\n\nWhat is the smallest value of \\(a\\) such that \\(P(X\\leq a) \\geq 0.5\\)?\n\n\n# let's take a look at the distribution function first:\ndist_df = data.frame(\n  a = 0:10,\n  p_x_lessthan_a = pbinom(0:10,10,0.7)\n)\ndist_df\n\n    a p_x_lessthan_a\n1   0   0.0000059049\n2   1   0.0001436859\n3   2   0.0015903864\n4   3   0.0105920784\n5   4   0.0473489874\n6   5   0.1502683326\n7   6   0.3503892816\n8   7   0.6172172136\n9   8   0.8506916541\n10  9   0.9717524751\n11 10   1.0000000000\n\n\n\n# can use \"q+dist\" to find such a\nquantile &lt;- qbinom(0.5,10,0.7)\nsprintf(\"a = %s\", quantile)\n\n[1] \"a = 7\"\n\n\n\n\n\n\n\n\nWhat if \\(X\\) is a continuous random variable?\n\n\n\nThen q+dist(\\(q\\)) is a one to one function giving precisely the \\(a\\) such that \\(P(X\\leq a)=q\\)."
  },
  {
    "objectID": "lab_3_markdown.html#linear-transformations-of-normal-random-variables",
    "href": "lab_3_markdown.html#linear-transformations-of-normal-random-variables",
    "title": "ST117 Lab 3",
    "section": "",
    "text": "We have that if \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\), then \\(aX+b\\sim \\mathcal{N}(a\\mu+b,a^2\\sigma^2)\\). This property is useful when we want to transform a standard \\(\\mathcal{N}(0,1)\\) to match a given set of mean and variance."
  },
  {
    "objectID": "lab_3_markdown.html#simulating-and-visualizing-binomial-distribution",
    "href": "lab_3_markdown.html#simulating-and-visualizing-binomial-distribution",
    "title": "ST117 Lab 3",
    "section": "2.1 Simulating and Visualizing Binomial Distribution",
    "text": "2.1 Simulating and Visualizing Binomial Distribution\n\nGenerate a random sample of 1000 observations from a binomial distribution with parameters \\(n=20\\) and \\(p=0.5\\), then create a histogram to visualize the distribution.\nCalculate the mean and standard deviation of the generated data. Compare these values with the theoretical mean and variance.\nFlipping a coin 20 times, where it has 50% chance of getting a head. The total number of head \\(X\\) follows a Binomial distribution with \\(n=20\\) and \\(p=0.5\\). Find the probability of getting between 5 and 12 heads when tossing 20 coins, which is sum of the orange bars."
  },
  {
    "objectID": "lab_3_markdown.html#calculating-probabilities-from-the-normal-distribution",
    "href": "lab_3_markdown.html#calculating-probabilities-from-the-normal-distribution",
    "title": "ST117 Lab 3",
    "section": "2.2 Calculating Probabilities from the Normal Distribution",
    "text": "2.2 Calculating Probabilities from the Normal Distribution\n\nSuppose \\(X \\sim \\mathcal{N}(0,1)\\), find the value \\(m\\) (green point) such that \\(P(X\\leq m)=0.95\\).\n\n\n\n\n\n\n\n\n\n\n\nGiven \\(X \\sim \\mathcal{N}(2,0.7^2)\\), find the probability of \\(X\\) being between 1 and 4.\nFind the probability \\(P(5\\leq X\\leq 12)\\) for \\(X \\sim \\mathcal{N}(10,5)\\)."
  },
  {
    "objectID": "lab_3_markdown.html#approximating-the-binomial-with-the-normal-distribution",
    "href": "lab_3_markdown.html#approximating-the-binomial-with-the-normal-distribution",
    "title": "ST117 Lab 3",
    "section": "2.3 Approximating the Binomial with the Normal distribution",
    "text": "2.3 Approximating the Binomial with the Normal distribution\n\nApproximate a Binomial distribution \\(Bin(20,0.5)\\) using a standard normally distributed \\(Z\\). Find the \\(z_1\\) and \\(z_2\\) such that \\(P(z_1\\leq Z\\leq z_2)\\) is the probability of getting between 5 and 10 heads.\n\n\n\n\n\n\nhint\n\n\n\nWe know that \\(Z\\sim\\mathcal{N}(0,1)\\), how do we linearly transform \\(Z\\) to match the mean and variance of a random variable from \\(Bin(20,0.5)\\)?\n\n\nUse R to calculate this probability using the standard normal distribution and check if it matches with Section 1(c)."
  },
  {
    "objectID": "lab_3_markdown.html#experiments",
    "href": "lab_3_markdown.html#experiments",
    "title": "ST117 Lab 3",
    "section": "3.1 Experiments",
    "text": "3.1 Experiments\n\nPlot \\(X\\) following a \\(\\text{Bin}(n,0.5)\\) for different values of \\(n=(3,10,25,100)\\). Also, plot the approximated normal distribution \\(Y \\sim \\mathcal{N}(np,npq)\\). We can observe how the normal distribution becomes a good approximation as n increases.\n\n\nsampleBin&lt;-function(n,p){\n  A&lt;-seq(-0.5,0.5+n)\n  x&lt;-0:n\n  binomial.pdf&lt;-dbinom(x,n,p)\n  tit&lt;-paste0(\"Histogram of X~Bin(\",n,\",\",p,\")\")\n  ymax&lt;-1.2*max(binomial.pdf)\n  mu&lt;-n*p\n  sigma&lt;-sqrt(n*p*(1-p))\n  y&lt;-seq(0,n,.1)\n  normal.pdf&lt;-dnorm(y,mu,sigma)\n  \n  plot(x,binomial.pdf,col=\"lightblue\",xlab = \"X\", ylab = \"P(X=x)\",main=tit, type=\"h\", \n       ylim = c(0,ymax),lwd=5)\n\n  lines(y,normal.pdf,type=\"l\",col=\"red\",lwd=2,lty=2)\n \n}\n\npar(mfrow=c(2,2))\nsampleBin(3,0.5)\nsampleBin(10,0.5)\nsampleBin(25,0.5)\nsampleBin(100,0.5)"
  },
  {
    "objectID": "lab_3_markdown.html#some-theory",
    "href": "lab_3_markdown.html#some-theory",
    "title": "ST117 Lab 3",
    "section": "3.2 Some theory",
    "text": "3.2 Some theory\n\nBinomial as a Sum of Bernoulli Trials\nThe Binomial distribution can be understood as the sum of independent and identically distributed Bernoulli trials. A Bernoulli trial is an experiment with exactly two possible outcomes: success (with probability \\(p\\)) and failure (with probability \\(1-p\\)). When we perform \\(n\\) such independent trials, the sum of successes follows a Binomial distribution, \\(\\text{Bin}(n, p)\\).\nMathematically, we have \\[\nX_\\text{Bin} = \\sum_{i =1}^n X_{\\text{Ber},i},\n\\]\nwhere \\(X_{\\text{Ber},i}\\sim^{i.i.d} \\operatorname{Bernoulli}(p)\\), and \\(X_\\text{Bin}\\sim \\text{Bin}(n, p)\\)\n\n\nCentral Limit Theorem\nThe Central Limit Theorem (CLT) states that, under certain conditions, the (normalised) sum of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the variables. In the context of the Binomial distribution, as the number of trials \\(n\\) becomes large, the distribution of the sum of the Bernoulli trials will tend towards a normal distribution.\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\nSuppose \\(X_1\\), \\(X_2\\), \\(\\dots\\) is a sequence of i.i.d. random variables with \\(\\mathbb{E}[X_1] = \\mu\\) and \\(\\operatorname{Var}[X_1] = \\sigma^2&lt;\\infty\\). Then, as \\(n\\) approaches infinity, the random variables \\(\\sqrt{n}(\\bar{X_n}-\\mu)\\) converges in distribution to a normal \\(\\mathcal{N(0,\\sigma^2)}\\):\n\\[\n\\sqrt{n}(\\bar{X_n}-\\mu) \\to \\mathcal{N(0,\\sigma^2)},\n\\] where \\(\\bar{X_n}=\\frac{1}{n}\\sum_{i=1}^n X_i\\)\n\n\n\n\nBoundary Conditions\nFor the convergence of a Binomial to a Normal distribution to be a good approximation, certain boundary conditions should be met:\n\nThe number of trials \\(n\\) should be large.\nNeither \\(p\\) nor \\(1-p\\) should be too small; a common rule of thumb is that both \\(np\\) and \\(n(1-p)\\) should be greater than 5.\n\nWhen these conditions are met, we can use the Normal distribution as an approximation for the Binomial distribution, greatly simplifying calculations in many cases.\n\\[\n\\text{Bin}(n, p) \\approx \\mathcal{N}(np, np(1-p))\n\\]\nThis approximation is particularly useful for calculating probabilities for large \\(n\\), where direct computation using the Binomial formula becomes impractical."
  },
  {
    "objectID": "lab_3_markdown.html#explorations",
    "href": "lab_3_markdown.html#explorations",
    "title": "ST117 Lab 3",
    "section": "3.3 Explorations",
    "text": "3.3 Explorations\nPlot \\(X\\) following a \\(\\text{Bin}(n,0.1)\\) for different values of \\(n=(3,10,25,100)\\). Check if the normal distribution is a good approximation.\n\nsampleBin&lt;-function(n,p){\n  A&lt;-seq(-0.5,0.5+n)\n  x&lt;-0:n\n  binomial.pdf&lt;-dbinom(x,n,p)\n  tit&lt;-paste0(\"Histogram of X~Bin(\",n,\",\",p,\")\")\n  ymax&lt;-1.2*max(binomial.pdf)\n  mu&lt;-n*p\n  sigma&lt;-sqrt(n*p*(1-p))\n  y&lt;-seq(0,n,.1)\n  normal.pdf&lt;-dnorm(y,mu,sigma)\n  \n  plot(x,binomial.pdf,col=\"lightblue\",xlab = \"X\", ylab = \"P(X=x)\",main=tit, type=\"h\", \n       ylim = c(0,ymax),lwd=5)\n\n  lines(y,normal.pdf,type=\"l\",col=\"red\",lwd=2,lty=2)\n \n\n}\n\npar(mfrow=c(2,2))\nsampleBin(3,0.1)\nsampleBin(10,0.1)\nsampleBin(25,0.1)\nsampleBin(100,0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nExplore the influence of \\(p\\) on convergence speed. Consider distribution like \\(Bin(100,0.1),\\ Bin(100,0.01),\\ Bin(10000,0.01)\\)."
  },
  {
    "objectID": "activity2_template.html",
    "href": "activity2_template.html",
    "title": "Activity 2 Presentation: Exploring Bivariate Data Relationships",
    "section": "",
    "text": "This presentation explores the relationship between two variables from a real-world dataset. Our objective is to determine if there exists a causal, no, or spurious relationship between these variables. This analysis is inspired by the Harvard Business Review article (“Beware Spurious Correlations” 2015) about the Spurious Correlation website (Vigen)."
  },
  {
    "objectID": "activity2_template.html#introduction",
    "href": "activity2_template.html#introduction",
    "title": "Activity 2 Presentation: Exploring Bivariate Data Relationships",
    "section": "",
    "text": "This presentation explores the relationship between two variables from a real-world dataset. Our objective is to determine if there exists a causal, no, or spurious relationship between these variables. This analysis is inspired by the Harvard Business Review article (“Beware Spurious Correlations” 2015) about the Spurious Correlation website (Vigen)."
  },
  {
    "objectID": "activity2_template.html#data-preparation",
    "href": "activity2_template.html#data-preparation",
    "title": "Activity 2 Presentation: Exploring Bivariate Data Relationships",
    "section": "Data Preparation",
    "text": "Data Preparation\nThe dataset used in this analysis was sourced from [describe data source here]. The variables of interest are [Variable 1] and [Variable 2], chosen because [briefly explain why].\n\n# Your R code to load (and preview) the dataset"
  },
  {
    "objectID": "activity2_template.html#data-visualization",
    "href": "activity2_template.html#data-visualization",
    "title": "Activity 2 Presentation: Exploring Bivariate Data Relationships",
    "section": "Data Visualization",
    "text": "Data Visualization\n\n# Create a scatterplot of your variables + any other plots you find necessary"
  },
  {
    "objectID": "activity2_template.html#discussion",
    "href": "activity2_template.html#discussion",
    "title": "Activity 2 Presentation: Exploring Bivariate Data Relationships",
    "section": "Discussion",
    "text": "Discussion\nThe plot(s) generated reveals [describe the overall pattern]. This pattern suggests that the relationship between Variable 1 and Variable 2 is [causal/no/spurious].\n\nRelationship Analysis\n\nForm of Relationship: The relationship appears to be [linear/non-linear/etc.], indicating [explain].\nCausality: Given the nature of the data, it is [likely/unlikely] that this relationship is causal because [reason].\nAlternative Explanations: It is also possible that [other variables/confounding factors] could explain this relationship.\n\n\n\nConclusion\nIn conclusion, the analysis of [Variable 1] and [Variable 2] provides [summarise findings]. While definitive conclusions about causality cannot be drawn without further information, the data suggests [final thoughts]."
  },
  {
    "objectID": "activity2_template.html#references-optional",
    "href": "activity2_template.html#references-optional",
    "title": "Activity 2 Presentation: Exploring Bivariate Data Relationships",
    "section": "References (optional)",
    "text": "References (optional)\n\n&lt;To display the references, you need to make sure that references.bib is in the same directory as this R Markdown file. The bibliography: references.bib line in the header tells R Markdown where to find your bibliography file.&gt;\n&lt;To add references, simply add entries of the same format in references.bib.&gt;\n\n\n\n&lt;To remove the references, you simply need to delete the line bibliography: references.bib in the header, and remove (“Beware Spurious Correlations” 2015) and (Vigen) in the introduction section.&gt;"
  },
  {
    "objectID": "lab_3_workbook.html",
    "href": "lab_3_workbook.html",
    "title": "ST117 Lab 3 Workbook",
    "section": "",
    "text": "Generate a random sample of 1000 observations from a binomial distribution with parameters \\(n=20\\) and \\(p=0.5\\), then create a histogram to visualize the distribution.\n\n\n# TODO: generate binomial samples\n\n\n# TODO: write down your codes to plot the histogram\n\n\nCalculate the mean and standard deviation of the generated data. Compare these values with the theoretical mean and variance.\n\n\n# TODO: calculate mean and variance\n\n\nFlipping a coin 20 times, where it has 50% chance of getting a head. The total number of head \\(X\\) follows a Binomial distribution with \\(n=20\\) and \\(p=0.5\\). Find the probability of getting between 5 and 12 heads when tossing 20 coins, which is sum of the orange bars.\n\n\n\n\n\n\n\n\n\n\n\n# TODO: calculate the probability"
  },
  {
    "objectID": "lab_3_workbook.html#simulating-and-visualizing-binomial-distribution",
    "href": "lab_3_workbook.html#simulating-and-visualizing-binomial-distribution",
    "title": "ST117 Lab 3 Workbook",
    "section": "",
    "text": "Generate a random sample of 1000 observations from a binomial distribution with parameters \\(n=20\\) and \\(p=0.5\\), then create a histogram to visualize the distribution.\n\n\n# TODO: generate binomial samples\n\n\n# TODO: write down your codes to plot the histogram\n\n\nCalculate the mean and standard deviation of the generated data. Compare these values with the theoretical mean and variance.\n\n\n# TODO: calculate mean and variance\n\n\nFlipping a coin 20 times, where it has 50% chance of getting a head. The total number of head \\(X\\) follows a Binomial distribution with \\(n=20\\) and \\(p=0.5\\). Find the probability of getting between 5 and 12 heads when tossing 20 coins, which is sum of the orange bars.\n\n\n\n\n\n\n\n\n\n\n\n# TODO: calculate the probability"
  },
  {
    "objectID": "lab_3_workbook.html#calculating-probabilities-from-the-normal-distribution",
    "href": "lab_3_workbook.html#calculating-probabilities-from-the-normal-distribution",
    "title": "ST117 Lab 3 Workbook",
    "section": "2. Calculating Probabilities from the Normal Distribution",
    "text": "2. Calculating Probabilities from the Normal Distribution\n\nSuppose \\(X \\sim \\text{N}(0,1)\\), find the value \\(m\\) (green point) such that \\(P(X\\leq m)=0.95\\).\n\n\n\n\n\n\n\n\n\n\n\n# TODO: find m with qnorm\n\n\nGiven \\(X \\sim \\text{N}(2,0.7^2)\\), find the probability of \\(X\\) being between 1 and 4.\n\n\n# TODO: calculate the probability\n\n\nFind the probability \\(P(5\\leq X\\leq 12)\\) for \\(X \\sim \\text{N}(10,5)\\).\n\n\n# TODO: calculate the probability"
  },
  {
    "objectID": "lab_3_workbook.html#approximating-the-binomial-with-the-normal-distribution",
    "href": "lab_3_workbook.html#approximating-the-binomial-with-the-normal-distribution",
    "title": "ST117 Lab 3 Workbook",
    "section": "3. Approximating the Binomial with the Normal distribution",
    "text": "3. Approximating the Binomial with the Normal distribution\nPlease write down the questions and answers yourself, following the format above."
  },
  {
    "objectID": "lab_4_workbook.html",
    "href": "lab_4_workbook.html",
    "title": "ST117 Lab 4 Workbook",
    "section": "",
    "text": "Include the pictures in R markdown with the following code, ![Name](path to the picture){width=50%}.\nExercise: Insert a image of your choice to the workbook.\nTODO: Please insert your image here\n\n\n\nThe mathematical typesetting is based on LaTeX. Below are some common LaTex syntax examples.\n\nSubscript \\(X_{i}\\): $X_{i}$\nSuperscript \\(X^{i}\\): $X^{i}$\nSum \\(\\sum_{i=1}^{n} X_{i}\\): $\\sum_{i=1}^{n} X_{i}$\nFraction \\(\\frac{a}{b}\\): $\\frac{a}{b}$\nExpectation \\(\\mathbb{E}[X]\\): $\\mathbb{E}[X]$\nVariance \\(\\operatorname{Var}\\): $\\operatorname{Var}$\nInfinity \\(\\infty\\): $\\infty$\nGreek letters \\(\\alpha\\): $\\alpha$\nAligning equations: use aligned\n\\[\n\\begin{aligned}\n\\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n&= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n&= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n&= \\lambda\n\\end{aligned}\n\\]\n$$\n\\begin{aligned}\n  \\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n  &= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n  &= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n  &= \\lambda\n\\end{aligned}\n$$\n\nExercise: Type out the following equation in LaTex:\n\n\n\nSecond moment of Poisson\n\n\nTODO: LaTex codes \\[\n% type out your equation here\n\\]"
  },
  {
    "objectID": "lab_4_workbook.html#inserting-images",
    "href": "lab_4_workbook.html#inserting-images",
    "title": "ST117 Lab 4 Workbook",
    "section": "",
    "text": "Include the pictures in R markdown with the following code, ![Name](path to the picture){width=50%}.\nExercise: Insert a image of your choice to the workbook.\nTODO: Please insert your image here"
  },
  {
    "objectID": "lab_4_workbook.html#mathematics-inside-rmarkdown",
    "href": "lab_4_workbook.html#mathematics-inside-rmarkdown",
    "title": "ST117 Lab 4 Workbook",
    "section": "",
    "text": "The mathematical typesetting is based on LaTeX. Below are some common LaTex syntax examples.\n\nSubscript \\(X_{i}\\): $X_{i}$\nSuperscript \\(X^{i}\\): $X^{i}$\nSum \\(\\sum_{i=1}^{n} X_{i}\\): $\\sum_{i=1}^{n} X_{i}$\nFraction \\(\\frac{a}{b}\\): $\\frac{a}{b}$\nExpectation \\(\\mathbb{E}[X]\\): $\\mathbb{E}[X]$\nVariance \\(\\operatorname{Var}\\): $\\operatorname{Var}$\nInfinity \\(\\infty\\): $\\infty$\nGreek letters \\(\\alpha\\): $\\alpha$\nAligning equations: use aligned\n\\[\n\\begin{aligned}\n\\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n&= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n&= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n&= \\lambda\n\\end{aligned}\n\\]\n$$\n\\begin{aligned}\n  \\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n  &= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n  &= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n  &= \\lambda\n\\end{aligned}\n$$\n\nExercise: Type out the following equation in LaTex:\n\n\n\nSecond moment of Poisson\n\n\nTODO: LaTex codes \\[\n% type out your equation here\n\\]"
  },
  {
    "objectID": "lab_4_workbook.html#data-generation",
    "href": "lab_4_workbook.html#data-generation",
    "title": "ST117 Lab 4 Workbook",
    "section": "Data Generation",
    "text": "Data Generation\nSuppose we have test scores for a population of 1000 students, expressed as percentages, generated from a \\(\\text{Beta}(2,5)\\) distribution. Create a data frame to store the names and scores of these students. Calculate the population mean and variance, and plot a histogram to visualize the distribution of the test scores.\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_4_workbook.html#mean-calculation",
    "href": "lab_4_workbook.html#mean-calculation",
    "title": "ST117 Lab 4 Workbook",
    "section": "Mean Calculation:",
    "text": "Mean Calculation:\nSuppose that we only have access to a sample of 100 scores (with replacement). Please generate this sample and calculate its mean to estimate the population mean. Compute the bias of this estimator.\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_4_workbook.html#simulation-analysis-with-replacement-vs-without-replacement",
    "href": "lab_4_workbook.html#simulation-analysis-with-replacement-vs-without-replacement",
    "title": "ST117 Lab 4 Workbook",
    "section": "Simulation Analysis: with replacement vs without replacement",
    "text": "Simulation Analysis: with replacement vs without replacement\n\nSuppose that we can repeat the survey process through 100,000 simulations, each sampling 100 students with replacement. Calculate the sample mean for each of the 100,000 simulations.\n\n\n# TODO: write your codes here\n\n\nCheck the mean, bias, and variance of the sample means.\n\n\n# TODO: write your codes here\n\n\nPlot a histogram of sample means. Compare the sample mean to a normal distribution using a Q-Q plot.\n\n\n# TODO: write your codes here\n\n\nSuppose we sample without replacement from the 100,000 simulations. Estimate the expectation, bias, and variance of the estimators. What did you learn about these quantities in your lectures? Type up the theoretical expressions of them with LaTex.\n\n\n# TODO: write your codes here\n\nTODO: Latex codes \\[\n% write your LaTex expressions here\n\\]"
  },
  {
    "objectID": "lab_4_workbook.html#assigning-groups",
    "href": "lab_4_workbook.html#assigning-groups",
    "title": "ST117 Lab 4 Workbook",
    "section": "Assigning groups",
    "text": "Assigning groups\nThe survey is conducted by two volunteer groups, 1 and 2, after we have randomly assigned students to these groups. A student is assigned to group 1 with probability \\(\\frac{2}{3}\\). Students attending the survey from group 1 receive a notebook, while those attending by group 2 receive a bottle. Create two columns to show which volunteer group conducted the survey and what gift the students received by sample() and ifelse().\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_4_workbook.html#trimmed-mean-optional",
    "href": "lab_4_workbook.html#trimmed-mean-optional",
    "title": "ST117 Lab 4 Workbook",
    "section": "Trimmed mean (optional)",
    "text": "Trimmed mean (optional)\nThe trimmed mean is a method to estimate a dataset’s central tendency by removing a specified percentage of the smallest and largest values before calculating the average of the remaining data. This technique helps reduce the impact of outliers, providing a more reliable measure of the dataset’s typical value, especially useful when data is skewed or contains extreme values. It combines the mean’s sensitivity to data changes with the median’s resistance to outliers, offering a robust tool for data analysis.\nIn R, we can calculate the trimmed mean via\n\nsample &lt;- pop[sample(nrow(pop), size=100,replace=TRUE),]\ntrim_means &lt;- mean(sample$scores, trim=0.2) # trim the smallest 10% and largest 10% before calculating the mean.\n\nAssume that our sampled data is contaminated with outliers: some students did not report their true score - a random selection of 5 student reported that their score is 1 regardless of their true score. Please include this contamination, and compare the mean and trimmed mean of your sample.\n\n# TODO: write your codes here"
  },
  {
    "objectID": "lab_9_markdown.html",
    "href": "lab_9_markdown.html",
    "title": "ST117 Lab 9",
    "section": "",
    "text": "Before we start, here is a list of a few useful sanity checks before submitting your final project:\n\nLine width: make sure that all codes are fully displayed and not cut out mid-line.\nReading datasets: check the default value of the col_name argument in your method. Use head to check if your data is imported properly.\nDealing with NAs: check if you have dealt with NAs consistently throughout the whole project, especially if different people handled different parts.\nEstimators: make sure that you estimators are in terms of the observed data - check the four quadrants of random vs fixed and unknown vs known.\nVariances: the var (and sd) function in R gives you the sample variance \\(S = \\frac{\\sum_i (X_i-\\bar{X})^2}{n-1}\\), while the MLE and MoM are \\(\\hat{\\sigma}^2 = \\frac{\\sum_i (X_i-\\bar{X})^2}{n}\\). Be mindful of which one should be used in your project.\n(If applicable) Make sure you have listed all your references. activity_2_template and references.bib give an example of how to include references in R markdown."
  },
  {
    "objectID": "lab_9_markdown.html#using-the-lm-function",
    "href": "lab_9_markdown.html#using-the-lm-function",
    "title": "ST117 Lab 9",
    "section": "Using the lm Function",
    "text": "Using the lm Function\nThe lm function in R is used for fitting linear models. It is a powerful tool for regression analysis, allowing researchers to understand the relationship between a dependent variable and one or more independent variables.\nThe basic syntax of the lm function is as follows:\n\nmodel &lt;- lm(formula, data)\n\n\nformula: describes the model (e.g., y ~ x indicates y is modeled as a function of x).\ndata: the data frame containing the variables mentioned in the formula."
  },
  {
    "objectID": "lab_9_markdown.html#example",
    "href": "lab_9_markdown.html#example",
    "title": "ST117 Lab 9",
    "section": "Example",
    "text": "Example\n\n# Load the mtcars dataset\ndata(mtcars)\n\nkable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n# Fit a linear model predicting mpg (miles per gallon) from wt (weight)\nmodel &lt;- lm(mpg ~ wt, data = mtcars)\n\n# Print the model to display basic informations\nprint(model)\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\n\n\nSummary Output\nThe summary function provides a comprehensive summary of the model fit.\n\n# Display the summary of the linear model\nsummary(model)\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n\nInterpretation:\n\n\n\n\n\n\n\nOutput Component\nExplanation\n\n\n\n\nCall\nShows the function call, including the formula and data set used. Useful for tracking the model configuration.\n\n\nResiduals\nSummary statistics (min, 1st Quartile, Median, 3rd Quartile, max) of residuals (observed - predicted values). Aids in assessing model fit.\n\n\nCoefficients - Estimate\nThe estimate for each coefficient, i.e. the slope and the intercept.\n\n\nCoefficients - Std. Error\nThe standard error of the coefficient estimate, with lower values indicating more precise estimates.\n\n\nCoefficients - t value\nThe t-statistic for each coefficient, used to assess the significance of the estimates. Calculated as Estimate/Std. Error.\n\n\nCoefficients - Pr(&gt;|t|)\nThe p-value for the coefficient’s t-test, indicating the significance of the estimates. Lower values suggest significant contributions of the variable.\n\n\nSignif. codes\nSymbols (***, **, *, .) representing p-value ranges. From &lt; 0.001 (strong evidence against the null hypothesis) to &gt;= 0.1 (weak evidence).\n\n\nResidual Standard Error\nMeasures the average distance that the observed values fall from the regression line. Lower values indicate a better fit.\n\n\nMultiple R-squared\nThe proportion of variance in the dependent variable explained by the model. Higher values indicate a better fit.\n\n\nAdjusted R-squared\nAdjusts R-squared for the number of predictors. Provides a more accurate measure of model goodness of fit for models with different numbers of predictors.\n\n\nF-statistic\nOverall measure of the model’s significance. Tests if at least one predictor variable has a non-zero coefficient.\n\n\nP-value\nP-value associated with the F-statistic. Indicates the overall statistical significance of the model. A low value suggests the model is statistically significant.\n\n\n\n\n\nDiagnostic Plots\nAfter fitting a model with lm, use the plot function to generate diagnostic plots.\n\n# Generate diagnostic plots\npar(mfrow = c(2, 2))\nplot(model)\n\n\n\n\n\n\n\n\nInterpretations:\n\n\n\n\n\n\n\nPlot\nInterpretation\n\n\n\n\nResiduals vs Fitted\nChecks the linearity assumption. Ideally, the residuals should be randomly scattered around 0, indicating that the model accurately captures the data’s trend.\n\n\nNormal Q-Q\nAssesses the normality of residuals. Points closely following the reference line suggest that residuals are normally distributed.\n\n\nScale-Location (or Spread-Location)\nEvaluates homoscedasticity, which is the equal spread of residuals across all levels of the fitted values. A horizontal line with equally spread points indicates homoscedasticity.\n\n\nResiduals vs Leverage\nIdentifies influential cases that might unduly affect the model’s predictions. Points far from the center suggest a high influence on the model estimate.\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\n\nPlease attempt these questions and write down your answers in the R Mardown workbook.\nRun your codes in your workbook and compare your results with your deskmate.\nKnit your workbook to publish a report in PDF or html."
  },
  {
    "objectID": "lab_9_markdown.html#linear-regression-model",
    "href": "lab_9_markdown.html#linear-regression-model",
    "title": "ST117 Lab 9",
    "section": "1. Linear Regression Model",
    "text": "1. Linear Regression Model\nConsider the regression model: \\[\ny_i= \\alpha + \\beta x_i + \\epsilon_i\n\\]\nwhere \\(\\epsilon_i \\sim \\text{N}(0,\\sigma^2)\\) for \\(i = 1,\\ldots,n\\). Here, y represents heights(in cm) and x represents weights(in kg).\nGiven a sample of heights and weights,\n\nx&lt;-c(82.62954, 66.73767, 83.29799, 82.72429, 74.14641, 54.60050, 60.71433,\n     67.05280, 69.94233, 94.04653)\ny&lt;-c(202.5511,166.1328,194.1981,197.4564,181.9675,146.2233,160.5469, 166.2354,\n     178.0746, 213.0961)\n\n\nFind the maximum likelihood estimates for \\(\\alpha\\) and \\(\\beta\\) based on the given sample (Refer to Monday-1 Week 8 Lecture notes).\nPlot a scatter plot of the sample and include the estimated regression line using the MLE of \\(\\alpha\\) and \\(\\beta\\). Providing the exact regression equation \\(y=50+1.8*x+\\epsilon\\), where \\(\\epsilon \\sim N(0,5^2)\\), add this line into the plot.\nGenerate 100 simulations and calculate 100 values of \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) using the regression \\(y=50+1.8*x+\\epsilon\\), where \\(\\epsilon \\sim N(0,5^2)\\) and \\(x \\sim N(70,10^2)\\). Calculate the variance of the MLE \\((\\hat{\\alpha},\\hat{\\beta})\\) using R and the formulas provided in Tuesday-1 Week 8 Lecture notes:\n\n\\[\n\\begin{aligned}\n& \\operatorname{Var}(\\hat{\\beta})=\\frac{\\sigma^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} \\\\\n& \\operatorname{Var}(\\hat{\\alpha})=\\sigma^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2}\\right)\n\\end{aligned}\n\\]\n\nFind the estimators’ variances as the sample size \\(n\\) increases, considering \\(n = 100, 1000, 10000\\)."
  },
  {
    "objectID": "lab_9_markdown.html#diagnostic-check",
    "href": "lab_9_markdown.html#diagnostic-check",
    "title": "ST117 Lab 9",
    "section": "2. Diagnostic Check",
    "text": "2. Diagnostic Check\n\nConsider women dataset which contains average heights and weights for American Women. Create a scatter plot of this data to examine the relationship between heights and weights. Is there evidence of a linear relationship?\n\n\n #access the dataset\ndata(women) #access the dataset\n\nhead(women)\n\n  height weight\n1     58    115\n2     59    117\n3     60    120\n4     61    123\n5     62    126\n6     63    129\n\n\n\nFit a linear model to the data and perform a regression diagnostics check, including standard linear model diagnostics."
  },
  {
    "objectID": "lab_4_markdown.html",
    "href": "lab_4_markdown.html",
    "title": "ST117 Lab 4",
    "section": "",
    "text": "1 minute per student\nR markdown template for this presentation\n\n\n\n\n\nsanity check\n\ndoes this make sense?\nis this what this question is asking?\ncross-check with your pod members!\n\nwork presentation style\n\nstructure: put the answers and codes for the same question together\ncomment your codes\n\ncreate tables for your data frame when it has many columns - use kable from knitr!\n\nlibrary(knitr)\ngrade_book &lt;- data.frame(\n  first_names=randomNames(288,which.names = \"first\"), \n  last_names=randomNames(288,which.names = \"last\"), \n  lab_groups=rep(1:16,times=18) # 16 groups of 18 students each\n) \nkable(head(grade_book))\n\n\n\n\nfirst_names\nlast_names\nlab_groups\n\n\n\n\nSaahira\nStrong\n1\n\n\nRifat\nal-Galla\n2\n\n\nKathleen\nJimenez\n3\n\n\nMuhsin\nColbeth\n4\n\n\nRobert\nByrnes\n5\n\n\nDavid\nMartinez\n6"
  },
  {
    "objectID": "lab_4_markdown.html#a1-activity-presentation-next-week",
    "href": "lab_4_markdown.html#a1-activity-presentation-next-week",
    "title": "ST117 Lab 4",
    "section": "",
    "text": "1 minute per student\nR markdown template for this presentation"
  },
  {
    "objectID": "lab_4_markdown.html#exercise-sheet-feedback-and-advice",
    "href": "lab_4_markdown.html#exercise-sheet-feedback-and-advice",
    "title": "ST117 Lab 4",
    "section": "",
    "text": "sanity check\n\ndoes this make sense?\nis this what this question is asking?\ncross-check with your pod members!\n\nwork presentation style\n\nstructure: put the answers and codes for the same question together\ncomment your codes\n\ncreate tables for your data frame when it has many columns - use kable from knitr!\n\nlibrary(knitr)\ngrade_book &lt;- data.frame(\n  first_names=randomNames(288,which.names = \"first\"), \n  last_names=randomNames(288,which.names = \"last\"), \n  lab_groups=rep(1:16,times=18) # 16 groups of 18 students each\n) \nkable(head(grade_book))\n\n\n\n\nfirst_names\nlast_names\nlab_groups\n\n\n\n\nSaahira\nStrong\n1\n\n\nRifat\nal-Galla\n2\n\n\nKathleen\nJimenez\n3\n\n\nMuhsin\nColbeth\n4\n\n\nRobert\nByrnes\n5\n\n\nDavid\nMartinez\n6"
  },
  {
    "objectID": "lab_4_markdown.html#inserting-images",
    "href": "lab_4_markdown.html#inserting-images",
    "title": "ST117 Lab 4",
    "section": "2.1 Inserting images",
    "text": "2.1 Inserting images\nInclude the pictures in R markdown with the following code, ![Name](path to the picture){width=50%}.\nExercise: Insert a image of your choice to the workbook.\n\n\n\nA picture of Squirrel"
  },
  {
    "objectID": "lab_4_markdown.html#mathematics-inside-rmarkdown",
    "href": "lab_4_markdown.html#mathematics-inside-rmarkdown",
    "title": "ST117 Lab 4",
    "section": "2.2 Mathematics inside RMarkdown",
    "text": "2.2 Mathematics inside RMarkdown\nThe mathematical typesetting is based on LaTeX. Below are some common LaTex syntax examples. A more comprehensive summary can be found on this page.\n\nSubscript \\(X_{i}\\): $X_{i}$\nSuperscript \\(X^{i}\\): $X^{i}$\nSum \\(\\sum_{i=1}^{n} X_{i}\\): $\\sum_{i=1}^{n} X_{i}$\nFraction \\(\\frac{a}{b}\\): $\\frac{a}{b}$\nExpectation \\(\\mathbb{E}[X]\\): $\\mathbb{E}[X]$\nVariance \\(\\operatorname{Var}\\): $\\operatorname{Var}$\nInfinity \\(\\infty\\): $\\infty$\nGreek letters \\(\\alpha\\): $\\alpha$\nAligning equations: use align\n\\[\n\\begin{align}\n\\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n&= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n&= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n&= \\lambda\n\\end{align}\n\\]\n$$\n\\begin{align}\n  \\mathbb{E}[X] &= \\sum_{x=0}^\\infty x\\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n  &= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\\\\n  &= \\lambda e^{-\\lambda} e^{\\lambda} \\\\\n  &= \\lambda\n\\end{align}\n$$\n\nExercise: Type out the following equation in LaTex:\n\n\n\nSecond moment of Poisson"
  },
  {
    "objectID": "lab_4_markdown.html#data-generation",
    "href": "lab_4_markdown.html#data-generation",
    "title": "ST117 Lab 4",
    "section": "3.1 Data Generation",
    "text": "3.1 Data Generation\nSuppose we have test scores for a population of 1000 students, expressed as percentages, generated from a \\(\\text{Beta}(2,5)\\) distribution. Create a data frame to store the names and scores of these students. Calculate the population mean and variance, and plot a histogram to visualize the distribution of the test scores."
  },
  {
    "objectID": "lab_4_markdown.html#mean-calculation",
    "href": "lab_4_markdown.html#mean-calculation",
    "title": "ST117 Lab 4",
    "section": "3.2 Mean Calculation:",
    "text": "3.2 Mean Calculation:\nSuppose that we only have access to a sample of 100 scores (with replacement). Please generate this sample and calculate its mean to estimate the population mean. Compute the bias of this estimator."
  },
  {
    "objectID": "lab_4_markdown.html#simulation-analysis-with-replacement-vs-without-replacement",
    "href": "lab_4_markdown.html#simulation-analysis-with-replacement-vs-without-replacement",
    "title": "ST117 Lab 4",
    "section": "3.3 Simulation Analysis: with replacement vs without replacement",
    "text": "3.3 Simulation Analysis: with replacement vs without replacement\n\nSuppose that we can repeat the survey process through 100,000 simulations, each sampling 100 students with replacement. Calculate the sample mean for each of the 100,000 simulations.\nCheck the mean, bias, and variance of the sample means.\nPlot a histogram of sample means. Compare the sample mean to a normal distribution using a Q-Q plot.\nSuppose we sample without replacement from the 100,000 simulations. Estimate the expectation, bias, and variance of the estimators. What did you learn about these quantities in your lectures? Type up the theoretical expressions of them with LaTex."
  },
  {
    "objectID": "lab_4_markdown.html#assigning-groups",
    "href": "lab_4_markdown.html#assigning-groups",
    "title": "ST117 Lab 4",
    "section": "3.4 Assigning groups",
    "text": "3.4 Assigning groups\nThe survey is conducted by two volunteer groups, 1 and 2, after we have randomly assigned students to these groups. A student is assigned to group 1 with probability \\(\\frac{2}{3}\\). Students attending the survey from group 1 receive a notebook, while those attending by group 2 receive a bottle. Create two columns to show which volunteer group conducted the survey and what gift the students received by sample() and ifelse()."
  },
  {
    "objectID": "lab_4_markdown.html#trimmed-mean-optional",
    "href": "lab_4_markdown.html#trimmed-mean-optional",
    "title": "ST117 Lab 4",
    "section": "3.5 Trimmed mean (optional)",
    "text": "3.5 Trimmed mean (optional)\nThe trimmed mean is a method to estimate a dataset’s central tendency by removing a specified percentage of the smallest and largest values before calculating the average of the remaining data. This technique helps reduce the impact of outliers, providing a more reliable measure of the dataset’s typical value, especially useful when data is skewed or contains extreme values. It combines the mean’s sensitivity to data changes with the median’s resistance to outliers, offering a robust tool for data analysis.\nIn R, we can calculate the trimmed mean via\n\nsample &lt;- pop[sample(nrow(pop), size=100,replace=TRUE),]\ntrim_means &lt;- mean(sample$scores, trim=0.2) # trim the smallest 10% and largest 10% before calculating the mean.\n\nAssume that our sampled data is contaminated with outliers: some students did not report their true score - a random selection of 5 student reported that their score is 1 regardless of their true score. Please include this contamination, and compare the mean and trimmed mean of your sample."
  },
  {
    "objectID": "lab_9_workbook.html",
    "href": "lab_9_workbook.html",
    "title": "ST117 Lab 9 Workbook",
    "section": "",
    "text": "Consider the regression model: \\[\ny_i= \\alpha + \\beta x_i + \\epsilon_i\n\\]\nwhere \\(\\epsilon_i \\sim \\text{N}(0,\\sigma^2)\\) for \\(i = 1,\\ldots,n\\). Here, y represents heights(in cm) and x represents weights(in kg).\nGiven a sample of heights and weights,\n\nx&lt;-c(82.62954, 66.73767, 83.29799, 82.72429, 74.14641, 54.60050, 60.71433,\n     67.05280, 69.94233, 94.04653)\ny&lt;-c(202.5511,166.1328,194.1981,197.4564,181.9675,146.2233,160.5469, 166.2354,\n     178.0746, 213.0961)\n\n\nFind the maximum likelihood estimates for \\(\\alpha\\) and \\(\\beta\\) based on the given sample.\n\n\n#TODO: write your codes here\n\n\nPlot a scatter plot of the sample and include the estimated regression line using the MLE of \\(\\alpha\\) and \\(\\beta\\). Providing the exact regression equation \\(y=50+1.8*x+\\epsilon\\), where \\(\\epsilon \\sim N(0,5^2)\\), add this line into the plot.\n\n\n#TODO: write your codes here\n\n\nGenerate 100 simulations and calculate 100 values of \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) using the regression \\(y=50+1.8*x+\\epsilon\\), where \\(\\epsilon \\sim N(0,5^2)\\) and \\(x \\sim N(70,10^2)\\). Calculate the variance of the MLE \\((\\hat{\\alpha},\\hat{\\beta})\\) using R and the formulas provided in Tuesday-1 Week 8 Lecture notes:\n\n\\[\n\\begin{aligned}\n& \\operatorname{Var}(\\hat{\\beta})=\\frac{\\sigma^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} \\\\\n& \\operatorname{Var}(\\hat{\\alpha})=\\sigma^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2}\\right)\n\\end{aligned}\n\\]\n\n#TODO: write your codes here\n\n\nFind the estimators’ variances as the sample size \\(n\\) increases, considering \\(n = 100, 1000, 10000\\).\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_9_workbook.html#linear-regression-model",
    "href": "lab_9_workbook.html#linear-regression-model",
    "title": "ST117 Lab 9 Workbook",
    "section": "",
    "text": "Consider the regression model: \\[\ny_i= \\alpha + \\beta x_i + \\epsilon_i\n\\]\nwhere \\(\\epsilon_i \\sim \\text{N}(0,\\sigma^2)\\) for \\(i = 1,\\ldots,n\\). Here, y represents heights(in cm) and x represents weights(in kg).\nGiven a sample of heights and weights,\n\nx&lt;-c(82.62954, 66.73767, 83.29799, 82.72429, 74.14641, 54.60050, 60.71433,\n     67.05280, 69.94233, 94.04653)\ny&lt;-c(202.5511,166.1328,194.1981,197.4564,181.9675,146.2233,160.5469, 166.2354,\n     178.0746, 213.0961)\n\n\nFind the maximum likelihood estimates for \\(\\alpha\\) and \\(\\beta\\) based on the given sample.\n\n\n#TODO: write your codes here\n\n\nPlot a scatter plot of the sample and include the estimated regression line using the MLE of \\(\\alpha\\) and \\(\\beta\\). Providing the exact regression equation \\(y=50+1.8*x+\\epsilon\\), where \\(\\epsilon \\sim N(0,5^2)\\), add this line into the plot.\n\n\n#TODO: write your codes here\n\n\nGenerate 100 simulations and calculate 100 values of \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) using the regression \\(y=50+1.8*x+\\epsilon\\), where \\(\\epsilon \\sim N(0,5^2)\\) and \\(x \\sim N(70,10^2)\\). Calculate the variance of the MLE \\((\\hat{\\alpha},\\hat{\\beta})\\) using R and the formulas provided in Tuesday-1 Week 8 Lecture notes:\n\n\\[\n\\begin{aligned}\n& \\operatorname{Var}(\\hat{\\beta})=\\frac{\\sigma^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} \\\\\n& \\operatorname{Var}(\\hat{\\alpha})=\\sigma^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2}\\right)\n\\end{aligned}\n\\]\n\n#TODO: write your codes here\n\n\nFind the estimators’ variances as the sample size \\(n\\) increases, considering \\(n = 100, 1000, 10000\\).\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_9_workbook.html#diagnostic-check",
    "href": "lab_9_workbook.html#diagnostic-check",
    "title": "ST117 Lab 9 Workbook",
    "section": "2. Diagnostic Check",
    "text": "2. Diagnostic Check\n\nConsider women dataset which contains average heights and weights for American Women. Create a scatter plot of this data to examine the relationship between heights and weights. Is there evidence of a linear relationship?\n\n\n #access the dataset\ndata(women) #access the dataset\n\nhead(women)\n\n  height weight\n1     58    115\n2     59    117\n3     60    120\n4     61    123\n5     62    126\n6     63    129\n\n\n\n#TODO: write your codes here\n\n\nFit a linear model to the data and perform a regression diagnostics check, including standard linear model diagnostics.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_2_markdown.html",
    "href": "lab_2_markdown.html",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "When we read a CSV file with read.csv, there is an argument header deciding whether it reads the first row as the column names of the variables.\nRecall that last time, we generated a random data frame of columns named “id” and “score” first.\n\ndata &lt;- data.frame(\n  id = 1:3,\n  score = sample(5:10, 3, replace = TRUE) # sample(list, n) allows you to sample number n values from list\n)\ndata\n\n  id score\n1  1     7\n2  2     5\n3  3     6\n\n\nNow, we write data into a CSV file\n\n# Write the data frame to a CSV file\nwrite.csv(data, \"sample_data.csv\", row.names = FALSE)\n\nIf we read with header=TRUE (default in this case), “id” and “score” are parsed as column names instead of variable values\n\ndata_read_header &lt;- read.csv(\"sample_data.csv\", header = TRUE)\ndata_read_header\n\n  id score\n1  1     7\n2  2     5\n3  3     6\n\n\nHowever, if we read with header=FALSE, then “id” and “score” are regarded as values\n\ndata_read_noheader &lt;- read.csv(\"sample_data.csv\", header = FALSE)\ndata_read_noheader\n\n  V1    V2\n1 id score\n2  1     7\n3  2     5\n4  3     6\n\n\nIn this case, you would run into problems if you simply take the first column of data_read:\n\ndata_read_noheader[,1]\n\n[1] \"id\" \"1\"  \"2\"  \"3\" \n\n\nYou also run into problems if you are getting a column by its name:\n\ndata_read_header$id\n\n[1] 1 2 3\n\n\n\ndata_read_noheader$id\n\nNULL\n\n\n\n\n\n\n\n\nNote\n\n\n\nheader is defaulted to TRUE if and only if the first row contains one fewer field than the number of columns. For further details, use ?read.csv to check the full documentation.\n\n\n\n\n\nThe R Console is an interactive platform for immediate execution of individual commands, ideal for exploratory data analysis and quick tests.\nIn contrast, R Scripts are non-interactive files where code can be written, saved, and executed in a structured and reproducible manner, suitable for complex and longer projects.\n\n\n\nWhen you find a useful R package that isn’t already installed on your system, you use install.packages() to download and install it. This is typically a one-time process for each package. For example, to install the ggplot2 package, you would use:\n\ninstall.packages(\"ggplot2\")\n\nEvery time you start a new R session and want to use a previously installed package, you need to load it using the library() function. This needs to be done at the beginning of your scripts to ensure that all functions from the package are available. For example:\n\nlibrary(ggplot2)\n\nThis command does not install the package again, but simply makes its functionality available in your current session.\n\n\n\nTo convert a string that represents a number into a numeric format, you can use the as.numeric() function. For example:\n\nnumbers_as_strings &lt;- c(\"1\", \"2\", \"3\")\nnumbers &lt;- as.numeric(numbers_as_strings)\n\nConversely, if you need to convert numbers to strings, perhaps for output formatting, use the as.character() function:\n\nnumbers &lt;- c(1, 2, 3)\nnumbers_as_strings &lt;- as.character(numbers)"
  },
  {
    "objectID": "lab_2_markdown.html#data-frame-header",
    "href": "lab_2_markdown.html#data-frame-header",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "When we read a CSV file with read.csv, there is an argument header deciding whether it reads the first row as the column names of the variables.\nRecall that last time, we generated a random data frame of columns named “id” and “score” first.\n\ndata &lt;- data.frame(\n  id = 1:3,\n  score = sample(5:10, 3, replace = TRUE) # sample(list, n) allows you to sample number n values from list\n)\ndata\n\n  id score\n1  1     7\n2  2     5\n3  3     6\n\n\nNow, we write data into a CSV file\n\n# Write the data frame to a CSV file\nwrite.csv(data, \"sample_data.csv\", row.names = FALSE)\n\nIf we read with header=TRUE (default in this case), “id” and “score” are parsed as column names instead of variable values\n\ndata_read_header &lt;- read.csv(\"sample_data.csv\", header = TRUE)\ndata_read_header\n\n  id score\n1  1     7\n2  2     5\n3  3     6\n\n\nHowever, if we read with header=FALSE, then “id” and “score” are regarded as values\n\ndata_read_noheader &lt;- read.csv(\"sample_data.csv\", header = FALSE)\ndata_read_noheader\n\n  V1    V2\n1 id score\n2  1     7\n3  2     5\n4  3     6\n\n\nIn this case, you would run into problems if you simply take the first column of data_read:\n\ndata_read_noheader[,1]\n\n[1] \"id\" \"1\"  \"2\"  \"3\" \n\n\nYou also run into problems if you are getting a column by its name:\n\ndata_read_header$id\n\n[1] 1 2 3\n\n\n\ndata_read_noheader$id\n\nNULL\n\n\n\n\n\n\n\n\nNote\n\n\n\nheader is defaulted to TRUE if and only if the first row contains one fewer field than the number of columns. For further details, use ?read.csv to check the full documentation."
  },
  {
    "objectID": "lab_2_markdown.html#r-script-vs-console",
    "href": "lab_2_markdown.html#r-script-vs-console",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "The R Console is an interactive platform for immediate execution of individual commands, ideal for exploratory data analysis and quick tests.\nIn contrast, R Scripts are non-interactive files where code can be written, saved, and executed in a structured and reproducible manner, suitable for complex and longer projects."
  },
  {
    "objectID": "lab_2_markdown.html#installing-and-loading-packages",
    "href": "lab_2_markdown.html#installing-and-loading-packages",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "When you find a useful R package that isn’t already installed on your system, you use install.packages() to download and install it. This is typically a one-time process for each package. For example, to install the ggplot2 package, you would use:\n\ninstall.packages(\"ggplot2\")\n\nEvery time you start a new R session and want to use a previously installed package, you need to load it using the library() function. This needs to be done at the beginning of your scripts to ensure that all functions from the package are available. For example:\n\nlibrary(ggplot2)\n\nThis command does not install the package again, but simply makes its functionality available in your current session."
  },
  {
    "objectID": "lab_2_markdown.html#converting-between-strings-and-mumbers",
    "href": "lab_2_markdown.html#converting-between-strings-and-mumbers",
    "title": "ST117 Lab 2",
    "section": "",
    "text": "To convert a string that represents a number into a numeric format, you can use the as.numeric() function. For example:\n\nnumbers_as_strings &lt;- c(\"1\", \"2\", \"3\")\nnumbers &lt;- as.numeric(numbers_as_strings)\n\nConversely, if you need to convert numbers to strings, perhaps for output formatting, use the as.character() function:\n\nnumbers &lt;- c(1, 2, 3)\nnumbers_as_strings &lt;- as.character(numbers)"
  },
  {
    "objectID": "lab_2_markdown.html#random-numbers-and-data-frame",
    "href": "lab_2_markdown.html#random-numbers-and-data-frame",
    "title": "ST117 Lab 2",
    "section": "3.1 Random numbers and data frame",
    "text": "3.1 Random numbers and data frame\n\n3.1.1 Generating Random Numbers and Names\n(i) Generate two vectors \\((v_1,v_2)\\) of 30 random integers each, where the elements in \\(v_1\\) are uniformly drawn from \\(\\{80,81,\\dots,100\\}\\), and the elements in \\(v_2\\) are uniformly drawn from \\(\\{60,61,\\dots, 90 \\}\\), with replacement.\n\n\n\n\n\n\nsolution\n\n\n\n\nv1 &lt;- sample(80:100, 30, replace = TRUE)\nv2 &lt;- sample(60:90, 30, replace = TRUE)\n\n\n\n(ii) Generate a vector of 30 random names using the randomNames() function. Remember to install the randomNames package and load it!\n\ninstall.packages(\"randomNames\")\nlibrary(\"randomNames\")\n\n\n\n\n\n\n\nHint\n\n\n\nset.seed() allows the code to be reproducible by setting a specific seed value. When a seed is set, the sequence generated remains deterministic.\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\nset.seed(21012024)\nnames &lt;- randomNames(30)\n\n\n\n\n\n3.1.2 Create a data frame\nWe aim to record the names, assignment marks, and exam marks of 30 students from course 1 in a table. Using the functions above, first generate these items randomly, then combine them into a data frame with three columns: “names”, “assignment”, and “exam”.\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1 &lt;- data.frame(\n  names = randomNames(30),\n  assignment = sample(80:100, 30, replace = TRUE), \n  exam = sample(60:90, 30, replace = TRUE))\n\n\n\n\n\n3.1.3 Deal with data frame\n(i) First, calculate the final marks for this course using the formula \\[\\text{Final mark} = 0.2\\times \\text{Assignment} + 0.8\\times \\text{Exam}\\] and add this information to a new column named finalMark.\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1$finalMark &lt;- (0.2*course1$assignment + 0.8*course1$exam)\n\n\n\n(ii) Can you find the student with the highest finalMark?\n\n\n\n\n\n\nHint\n\n\n\n\nYou may consider sorting your data frame in descending order by the values of finalMarks - look up the different between sort and order!\nAlternatively, you can use the arrange function in the dplyr package for this task (optional).\n\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1[order(course1$finalMark, decreasing = TRUE),][1,]\n\n          names assignment exam finalMark\n17 Hagen, Sally        100   90        92\n\n# alternatively\ncourse1[order(course1$finalMark, decreasing = TRUE)[1],]\n\n          names assignment exam finalMark\n17 Hagen, Sally        100   90        92\n\n\nUsing dplyr:\n\ninstall.packages(\"dplyr\")\nlibrary(\"dplyr\")\n\n\ncourse1 %&gt;% arrange(desc(finalMark)) %&gt;% head(1) # %&gt;% is a pipe, which takes the output of the expression on its left and passes it as the first argument to the function on its right\n\n         names assignment exam finalMark\n1 Hagen, Sally        100   90        92\n\n\n\n\n(iii) Next, calculate the means of assignment, exam, and finalMarks, respectively.\n\n\n\n\n\n\nsolution\n\n\n\n\nround(mean(course1$assignment))\n\n[1] 91\n\nround(mean(course1$exam))\n\n[1] 76\n\nround(mean(course1$finalMark))\n\n[1] 79\n\n\n\nround(apply(X = course1[,2:4], MARGIN = 2, FUN = mean))\n\nassignment       exam  finalMark \n        91         76         79 \n\n\n\ncourse1 %&gt;%\n  summarize(across(c(2,3,4),mean)) %&gt;% round()\n\n  assignment exam finalMark\n1         91   76        79\n\n\n\n\n(iv) Then, randomly pick 10 students and set then to have chosen course 2. The other students have not chosen this course. Please add a column course2 to indicate their choice (0 for yes,1 for no).\n\n\n\n\n\n\nsolution\n\n\n\n\nrandom_numbers&lt;-sample(1:30,10,replace = FALSE)\ncourse1$course2&lt;- 0\ncourse1[c(random_numbers),]$course2&lt;-1\n\n\n\n(v) Finally, find the students with marks above 85 and who haven’t chosen course 2 by extracting values from the names column. You can also use the apply() function for this purpose. Verify if these two methods give the same results.\n\n\n\n\n\n\nsolution\n\n\n\n\ncourse1[course1$finalMark&gt;85 & course1$course2==0,]$names\n\n[1] \"Mcdonald, Demetri\" \"Gonzalez, Marissa\" \"Hagen, Sally\"     \n[4] \"Aragon, Faustina\"  \"Dubus, Jesse\"      \"Ash, Richard\"     \n\n\n\ncheck&lt;-function(x){\n  value &lt;- x[1]&gt;85 & x[2]==0\n  return(value)\n}\n\nfilter&lt;-apply(X = course1[,c(4,5)], 1, FUN = check)\ncourse1[filter,]$names\n\n[1] \"Mcdonald, Demetri\" \"Gonzalez, Marissa\" \"Hagen, Sally\"     \n[4] \"Aragon, Faustina\"  \"Dubus, Jesse\"      \"Ash, Richard\""
  },
  {
    "objectID": "lab_2_markdown.html#define-a-function",
    "href": "lab_2_markdown.html#define-a-function",
    "title": "ST117 Lab 2",
    "section": "3.2 Define a function",
    "text": "3.2 Define a function\nRecall that the Fibonacci sequence is defined by recurrent relations:\n\\(F_0=0,\\ F_1=1,\\ F_n=F_{n-1}+F_{n-2}\\).\nDefine a function to produce the nth Fibonacci number with or without a loop.\n\n\n\n\n\n\nsolution\n\n\n\nfor loop\n\nfb&lt;-function(n){\n  f&lt;-c(0,1)\n  if (n&gt;1){\n  for (i in 2:n){\n    f[i+1] &lt;- f[i] + f[i-1]\n  }}\n  return(f[n+1])\n}\n\nwithout for loop\n\nfb&lt;-function(n){\n  if(n==0){\n    return(0)\n  }\n  if(n==1){\n    return(1)\n  }\n  fb(n-1)+fb(n-2) #iterate until we meet the boundary conditions\n}"
  },
  {
    "objectID": "lab_2_markdown.html#uniform-distribution-and-histogram",
    "href": "lab_2_markdown.html#uniform-distribution-and-histogram",
    "title": "ST117 Lab 2",
    "section": "3.3 Uniform distribution and histogram",
    "text": "3.3 Uniform distribution and histogram\nSimulate 1000 samples from a uniform distribution \\(X\\sim U[0,1]\\) and create a histogram of the generated sequence. Overlay the histogram on the probability density function - does the histogram reflect the density well?\n\n\n\n\n\n\nHint\n\n\n\n\nYou can look up dunif(), which defines the probability density function of a uniform distribution.\nTo plot the histogram, you can simply use the hist function - alternatively, you can try the ggplot2 package.\n\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\n# generate the samples\nnum_sample &lt;- 1000 # you can try different values of num_sample\nsample &lt;- runif(n=num_sample,min=0,max=1)\n\n\n# get 100 evenly spaced values between -0.25 and 1.25 to plot the probability density function of the uniform distribution\nx &lt;- seq(-0.25, 1.25, length.out=100)\n\n#plotting the histogram\ntitle &lt;- sprintf(\"Histogram of %d simulations from X~U(%d,%d)\", num_sample, 0, 1)\nhist(sample, main = title, xlim = c(-0.5, 1.5), xlab = \"x\", prob = TRUE,col=\"lightblue\", ylab=\"f (x)\")\nlines(x, dunif(x,min=0,max=1), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nWith ggplot2:\n\n# Load ggplot2 library\nlibrary(ggplot2)\n\n# Create a data frame for the samples\ndf &lt;- data.frame(sample)\n\n# Create the histogram and overlay the probability density function\nggplot(df, aes(x = sample)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 0.08, fill = \"lightblue\", colour = \"black\") + \n  # here (y = after_stat(density)) means that we map the y-axis aesthetic to the density of the data, rather than the count, which is the default.\n  stat_function(fun = dunif, xlim = c(-0.25, 1.25), args = list(min = 0, max = 1), colour = \"red\", linewidth = 1) +\n  labs(title = sprintf(\"Histogram of %d simulations from X~U(%d,%d)\", num_sample, 0, 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\n\nIf we increase the number of simulations, does the fit improve?"
  },
  {
    "objectID": "lab_2_markdown.html#problem-statement",
    "href": "lab_2_markdown.html#problem-statement",
    "title": "ST117 Lab 2",
    "section": "Problem Statement",
    "text": "Problem Statement\nA and B are tossing a fair coin. A wins if HHH appears first; B wins if HTH appears first. Who is more likely to win?"
  },
  {
    "objectID": "lab_2_markdown.html#simulation-code",
    "href": "lab_2_markdown.html#simulation-code",
    "title": "ST117 Lab 2",
    "section": "Simulation Code",
    "text": "Simulation Code\nWe can write some codes to simulate the game\n\nsimulate_coin_toss &lt;- function(sequence_a, sequence_b, num_simulations = 1000) {\n  wins_a &lt;- 0\n  wins_b &lt;- 0\n\n  # play the game num_simulations times\n  for (i in 1:num_simulations) {\n    \n    # keep tossing until there is a winner\n    coin_sequence &lt;- \"\"\n    while (!grepl(sequence_a, coin_sequence) && !grepl(sequence_b, coin_sequence)) {\n      coin_sequence &lt;- paste0(coin_sequence, sample(c(\"H\", \"T\"), 1, replace = TRUE))\n    }\n    \n    # record the winner\n    if (grepl(sequence_a, coin_sequence)) {\n      wins_a &lt;- wins_a + 1\n    } else {\n      wins_b &lt;- wins_b + 1\n    }\n  }\n\n  # use the number of wins to estimate the winning probability\n  prob_a_wins &lt;- wins_a / num_simulations\n  prob_b_wins &lt;- wins_b / num_simulations\n\n  return(c(prob_a_wins, prob_b_wins))\n}\n\n# Call the function\nsimulate_coin_toss(\"HHH\", \"HTH\")\n\n[1] 0.39 0.61\n\n\n\n\n\n\n\n\nYour turn\n\n\n\n\nCan you write some codes to estimate the expected number of tosses needed until a certain player gets a win?\nCan you prove your winning probabilities algebraically?\n\n\n\n\n\n\n\n\n\nsolution\n\n\n\n\n# Function to calculate expected number of tosses\nexpected_tosses &lt;- function(sequence, num_simulations = 1000) {\n  toss_counts &lt;- numeric(num_simulations)\n\n  for (i in 1:num_simulations) {\n    coin_sequence &lt;- \"\"\n    toss_count &lt;- 0\n\n    while (!grepl(sequence, coin_sequence)) {\n      coin_sequence &lt;- paste0(coin_sequence, sample(c(\"H\", \"T\"), 1, replace = TRUE))\n      toss_count &lt;- toss_count + 1\n    }\n\n    toss_counts[i] &lt;- toss_count\n  }\n\n  mean(toss_counts)\n}\n\n# Calculate for sequences \"HHH\" and \"HTH\"\nexpected_tosses(\"HHH\")\n\n[1] 13.994\n\nexpected_tosses(\"HTH\")\n\n[1] 9.572"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website is created by Mengqi Chen at Department of Statistics, University of Warwick in term 2, 2024. It is put together with Quarto, which is an open-source scientific and technical publishing system designed to create dynamic and reproducible documents. The markdown files for the webpages can be found on my GitHub Repository for this courese.\nFor feedback on the lab sessions please fill out the anonymous feedback form. For corrections and comments on this site, please email me."
  },
  {
    "objectID": "lab_1_markdown.html",
    "href": "lab_1_markdown.html",
    "title": "ST117 Lab 1",
    "section": "",
    "text": "Welcome to ST117 Introduction to Statistical Modelling Lab 1!\nIn this lab session, we will focus on how to collect, save, and read data in R. We will also discuss some ways to manipulate and visualise our datasets. You will also have the chance to share and present the data you have collected with your deskmates!\n\n\n\n\n\n\nAbout me\n\nEmail: mengqi.chen.2@warwick.ac.uk\nRoom: MB3.14"
  },
  {
    "objectID": "lab_1_markdown.html#saving-data-into-.csv-files",
    "href": "lab_1_markdown.html#saving-data-into-.csv-files",
    "title": "ST117 Lab 1",
    "section": "2.1 Saving data into .csv Files",
    "text": "2.1 Saving data into .csv Files\nHere’s a basic example of how to save a dataset into a .csv file in R:\n\n# Create a sample data frame\ndata &lt;- data.frame(\n  id = 1:10,\n  score = runif(10, min=0, max=100)\n)\n\n# Write the data frame to a CSV file\nwrite.csv(data, \"sample_data.csv\", row.names = FALSE)"
  },
  {
    "objectID": "lab_1_markdown.html#reading-csv-files",
    "href": "lab_1_markdown.html#reading-csv-files",
    "title": "ST117 Lab 1",
    "section": "2.2 Reading CSV Files",
    "text": "2.2 Reading CSV Files\nTo read a CSV file into R:\n\n# Read the CSV file\ndata_read &lt;- read.csv(\"sample_data.csv\", header = FALSE)"
  },
  {
    "objectID": "lab_1_markdown.html#finding-data-online",
    "href": "lab_1_markdown.html#finding-data-online",
    "title": "ST117 Lab 1",
    "section": "2.3 Finding data online",
    "text": "2.3 Finding data online\nDatasets can also be found in various online repositories, such as:\n\nKaggle is a popular platform for data science competitions, but it also hosts a wide variety of datasets. These datasets cover a range of topics and complexities and can be a great starting point for projects in statistical modelling, data science, and machine learning\nUCI Machine Learning Repository: The University of California, Irvine, maintains a repository of datasets specifically for machine learning. These datasets are well-documented and have been used in numerous academic papers, making them ideal for research.\n…\n\n\n\n\n\n\n\nYour turn!\n\n\n\n\nPlease share your A0-collect! datasets to your deskmate - you could use email, link sharing, USB, etc.\nIntroduce your datasets to each other - how have you collected the data? What questions are you trying to answer with your data?\nAfter you have received your deskmate’s datasets, try to load them into your R workspace."
  },
  {
    "objectID": "lab_1_markdown.html#meet-the-penguins",
    "href": "lab_1_markdown.html#meet-the-penguins",
    "title": "ST117 Lab 1",
    "section": "Meet the penguins",
    "text": "Meet the penguins\n\nThe penguins data from the palmerpenguins package contains size measurements for 344 penguins from three species observed on three islands in the Palmer Archipelago, Antarctica.\nWe will first install and load the packages:\n\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\n\nLet’s take a look at the penguins data:\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nWhat if we are interested in some specific aspects of the penguins?\n\nCalculate the mean body mass of penguins (similarly, you can use var for variance and median for median)\n\nmean(penguins$body_mass_g, na.rm = TRUE) # na.rm indicates whether we remove the NA values\n\n[1] 4201.754\n\n\nGet the 5 largest body masses\n\nhead(sort(penguins$body_mass_g, decreasing=TRUE), 5)\n\n[1] 6300 6050 6000 6000 5950\n\n\n\n\n\n\n\n\n\n*Introducing: dplyr package\n\n\n\nIn data science, dplyr is a very popular package. It is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges. To install and load dplyr:\n\n# Load the dplyr package for data manipulation\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\n\n\nWith dplyr, we can do more fun things with our dataset!\n\nCount how many penguins are in each species\n\ncount(penguins, species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nFilter the datasets to get the data for female Gentoos only:\n\nfilter(penguins, sex == \"female\", species == \"Gentoo\")\n\n# A tibble: 58 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           48.7          14.1               210        4450\n 3 Gentoo  Biscoe           46.5          13.5               210        4550\n 4 Gentoo  Biscoe           45.4          14.6               211        4800\n 5 Gentoo  Biscoe           43.3          13.4               209        4400\n 6 Gentoo  Biscoe           40.9          13.7               214        4650\n 7 Gentoo  Biscoe           45.5          13.7               214        4650\n 8 Gentoo  Biscoe           45.8          14.6               210        4200\n 9 Gentoo  Biscoe           42            13.5               210        4150\n10 Gentoo  Biscoe           46.2          14.5               209        4800\n# ℹ 48 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nGet the mean body mass of penguins by species\n\nsummarise(penguins, mean_body_mass = mean(body_mass_g, na.rm = TRUE),\n            .by = species)\n\n# A tibble: 3 × 2\n  species   mean_body_mass\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Adelie             3701.\n2 Gentoo             5076.\n3 Chinstrap          3733.\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\n\nUse these functions, or other ones that you like, investigate your and your deskmate’s datasets!\n\nIf you run into any problems, try solving them by checking the documentation, using the help function, and discussing with each other!\n\nShare your findings with your deskmate."
  },
  {
    "objectID": "lab_7_workbook.html",
    "href": "lab_7_workbook.html",
    "title": "ST117 Lab 7 Workbook",
    "section": "",
    "text": "Generate a sample from the linear regression model:\n\\[\nY = 2X + \\varepsilon, \\ \\varepsilon \\sim \\mathcal{N}(0,5)\n\\]\n\n#TODO: write your codes here\n\n\nFind the regression line to predict \\(\\hat{y}\\) by \\(x\\), i.e. find \\(\\hat{a}_1\\), \\(\\hat{b}_1\\) such that\n\n\\[\nY = \\hat{b}_1 X + \\hat{a} _1\n\\]\nmanually using the covraiance and correlation estimators. Then verify the values using the lm function in R.\n\n#TODO: write your codes here\n\n\nFind the regression line to predict \\(\\hat{x}\\) by \\(y\\), i.e. find \\(\\hat{a}_2\\), \\(\\hat{b}_2\\) such that\n\n\\[\nX = \\hat{b}_2 Y + \\hat{a}_2\n\\]\nmanually using the covraiance and correlation estimators. Then verify the values using the lm function in R.\n\n#TODO: write your codes here\n\n\nPlot the data along with the two regression lines. Which regression line appears to be better?\n\n\n#TODO: write your codes here\n\n\nThe Least Squared Estimation can also help us derive the estimates of \\(\\hat{a}\\) and \\(\\hat{b}\\). We just need to find the value of \\(a\\) and \\(b\\) that minimizes the following expression: \\[\n\\sum_{i=1}^{n} \\Big( y_i-(a+bx_i) \\Big)^2\n\\] Hint: Use the optim function.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_7_workbook.html#linear-regression-model",
    "href": "lab_7_workbook.html#linear-regression-model",
    "title": "ST117 Lab 7 Workbook",
    "section": "",
    "text": "Generate a sample from the linear regression model:\n\\[\nY = 2X + \\varepsilon, \\ \\varepsilon \\sim \\mathcal{N}(0,5)\n\\]\n\n#TODO: write your codes here\n\n\nFind the regression line to predict \\(\\hat{y}\\) by \\(x\\), i.e. find \\(\\hat{a}_1\\), \\(\\hat{b}_1\\) such that\n\n\\[\nY = \\hat{b}_1 X + \\hat{a} _1\n\\]\nmanually using the covraiance and correlation estimators. Then verify the values using the lm function in R.\n\n#TODO: write your codes here\n\n\nFind the regression line to predict \\(\\hat{x}\\) by \\(y\\), i.e. find \\(\\hat{a}_2\\), \\(\\hat{b}_2\\) such that\n\n\\[\nX = \\hat{b}_2 Y + \\hat{a}_2\n\\]\nmanually using the covraiance and correlation estimators. Then verify the values using the lm function in R.\n\n#TODO: write your codes here\n\n\nPlot the data along with the two regression lines. Which regression line appears to be better?\n\n\n#TODO: write your codes here\n\n\nThe Least Squared Estimation can also help us derive the estimates of \\(\\hat{a}\\) and \\(\\hat{b}\\). We just need to find the value of \\(a\\) and \\(b\\) that minimizes the following expression: \\[\n\\sum_{i=1}^{n} \\Big( y_i-(a+bx_i) \\Big)^2\n\\] Hint: Use the optim function.\n\n\n#TODO: write your codes here"
  },
  {
    "objectID": "lab_7_workbook.html#mean-squared-error",
    "href": "lab_7_workbook.html#mean-squared-error",
    "title": "ST117 Lab 7 Workbook",
    "section": "2. Mean Squared Error",
    "text": "2. Mean Squared Error\nConsider a random sample \\(X_1,X_2,\\ldots,X_n\\) from a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). We have the following two estimators of the population variance obtained from the given sample information. From our previous lab, we derived the Maximum Likelihood Estimator(MLE) of the population variance as: \\[\n1.\\ \\hat{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^{n}(X_i-\\overline{X})^2.\n\\] Additionally, we have the sample variance given by: \\[\n2.\\ s^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\overline{X})^2,\n\\] where \\(\\overline{X}\\) represents the sample mean.\n\nSimulate a sample of 10 data from \\(\\text{N}(160,10^2)\\). Calculate the values of these two estimators and their Mean Squared Error(MSE).\n\n\n#TODO: write your codes here\n\n\nTry sample sizes of 100, 1000 and 10000, and show the results in a table. Can you provide an interpretation?\n\n\n#TODO: write your codes here"
  }
]